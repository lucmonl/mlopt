{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/lucmon/lucmon/anaconda3/envs/mlopt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForMultipleChoice,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"roberta-base\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "        model_name,\n",
    "        #cache_dir=model_args.cache_dir,\n",
    "        revision=\"main\",\n",
    "        use_auth_token=None,\n",
    "    )\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(\n",
    "        model_name,\n",
    "        from_tf=bool(\".ckpt\" in model_name),\n",
    "        config=config,\n",
    "        #cache_dir=model_args.cache_dir,\n",
    "        revision=\"main\",\n",
    "        use_auth_token=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "/u/lucmon/lucmon/anaconda3/envs/mlopt/lib/python3.11/site-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..', 'arch'))\n",
    "\n",
    "# Add to sys.path if not already present\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from lora import add_adapters_dataset\n",
    "\n",
    "model , output_layer_name, Lora_Config = add_adapters_dataset(model_name, model, 16, 16, lora_freeze_a=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "???\n",
      "A\n",
      "B\n",
      "torch.Size([16, 768]) torch.Size([768, 16])\n"
     ]
    }
   ],
   "source": [
    "base_name = \"base_model.model.roberta.encoder.layer.0.attention.self.value.base_layer.weight\"\n",
    "#base_name = \"base_model.model.roberta.encoder.layer.0.attention.self.value.weight\"\n",
    "def base_to_lora_name(base_name):\n",
    "    lora_A_name = base_name.replace(\"base_layer\", \"lora_A.default\")\n",
    "    lora_B_name = base_name.replace(\"base_layer\", \"lora_B.default\")\n",
    "    return lora_A_name, lora_B_name\n",
    "lora_A_name, lora_B_name = base_to_lora_name(base_name)\n",
    "\n",
    "#lora_A_name, lora_B_name = None, None\n",
    "for name, param in model.named_parameters():\n",
    "    if name == base_name:\n",
    "        print(\"???\")\n",
    "        base_param = param.clone()\n",
    "    if name == lora_A_name:\n",
    "        print(\"A\")\n",
    "        lora_A_param = param\n",
    "    if name == lora_B_name:\n",
    "        print('B')\n",
    "        lora_B_param = param\n",
    "print(lora_A_param.shape, lora_B_param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_A_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "lora_B_param.data = torch.randn_like(lora_B_param)\n",
    "\n",
    "scaling = 1\n",
    "my_product = scaling * lora_B_param @ lora_A_param\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_base_name = \"roberta.encoder.layer.0.attention.self.value.weight\"\n",
    "for name, param in merged_model.named_parameters():\n",
    "    if name == merged_base_name:\n",
    "        real_update = param - base_param\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0560, -0.0255,  0.1228,  ...,  0.0728, -0.1704,  0.0258],\n",
      "        [ 0.0490, -0.1293, -0.0183,  ..., -0.0340, -0.0298,  0.1013],\n",
      "        [ 0.0850,  0.0555, -0.0552,  ...,  0.1703, -0.1314, -0.1007],\n",
      "        ...,\n",
      "        [-0.1876,  0.0186,  0.0640,  ..., -0.0252,  0.0345, -0.1034],\n",
      "        [ 0.0117, -0.0402,  0.0104,  ..., -0.0239,  0.0612,  0.0206],\n",
      "        [ 0.0506,  0.0426,  0.0024,  ...,  0.0611, -0.1517, -0.1562]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(my_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0560, -0.0255,  0.1228,  ...,  0.0728, -0.1704,  0.0258],\n",
      "        [ 0.0490, -0.1293, -0.0183,  ..., -0.0340, -0.0298,  0.1013],\n",
      "        [ 0.0850,  0.0555, -0.0552,  ...,  0.1703, -0.1314, -0.1007],\n",
      "        ...,\n",
      "        [-0.1876,  0.0186,  0.0640,  ..., -0.0252,  0.0345, -0.1034],\n",
      "        [ 0.0117, -0.0402,  0.0104,  ..., -0.0239,  0.0612,  0.0206],\n",
      "        [ 0.0506,  0.0426,  0.0024,  ...,  0.0611, -0.1517, -0.1562]])\n"
     ]
    }
   ],
   "source": [
    "print(real_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.roberta.embeddings.word_embeddings.weight\n",
      "base_model.model.roberta.embeddings.position_embeddings.weight\n",
      "base_model.model.roberta.embeddings.token_type_embeddings.weight\n",
      "base_model.model.roberta.embeddings.LayerNorm.weight\n",
      "base_model.model.roberta.embeddings.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.key.weight\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.key.bias\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.0.attention.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.0.attention.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.0.intermediate.dense.weight\n",
      "base_model.model.roberta.encoder.layer.0.intermediate.dense.bias\n",
      "base_model.model.roberta.encoder.layer.0.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.0.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.0.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.0.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.key.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.key.bias\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.1.intermediate.dense.weight\n",
      "base_model.model.roberta.encoder.layer.1.intermediate.dense.bias\n",
      "base_model.model.roberta.encoder.layer.1.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.1.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.1.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.1.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.key.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.key.bias\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.2.intermediate.dense.weight\n",
      "base_model.model.roberta.encoder.layer.2.intermediate.dense.bias\n",
      "base_model.model.roberta.encoder.layer.2.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.2.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.2.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.2.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.key.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.key.bias\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.3.intermediate.dense.weight\n",
      "base_model.model.roberta.encoder.layer.3.intermediate.dense.bias\n",
      "base_model.model.roberta.encoder.layer.3.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.3.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.3.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.3.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.key.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.key.bias\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.4.intermediate.dense.weight\n",
      "base_model.model.roberta.encoder.layer.4.intermediate.dense.bias\n",
      "base_model.model.roberta.encoder.layer.4.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.4.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.4.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.4.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.key.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.key.bias\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.5.intermediate.dense.weight\n",
      "base_model.model.roberta.encoder.layer.5.intermediate.dense.bias\n",
      "base_model.model.roberta.encoder.layer.5.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.5.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.5.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.5.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.key.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.key.bias\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.6.intermediate.dense.weight\n",
      "base_model.model.roberta.encoder.layer.6.intermediate.dense.bias\n",
      "base_model.model.roberta.encoder.layer.6.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.6.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.6.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.6.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.key.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.key.bias\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.7.intermediate.dense.weight\n",
      "base_model.model.roberta.encoder.layer.7.intermediate.dense.bias\n",
      "base_model.model.roberta.encoder.layer.7.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.7.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.7.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.7.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.key.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.key.bias\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.8.intermediate.dense.weight\n",
      "base_model.model.roberta.encoder.layer.8.intermediate.dense.bias\n",
      "base_model.model.roberta.encoder.layer.8.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.8.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.8.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.8.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.key.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.key.bias\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.9.intermediate.dense.weight\n",
      "base_model.model.roberta.encoder.layer.9.intermediate.dense.bias\n",
      "base_model.model.roberta.encoder.layer.9.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.9.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.9.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.9.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.key.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.key.bias\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.10.intermediate.dense.weight\n",
      "base_model.model.roberta.encoder.layer.10.intermediate.dense.bias\n",
      "base_model.model.roberta.encoder.layer.10.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.10.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.10.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.10.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.key.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.key.bias\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.base_layer.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "base_model.model.roberta.encoder.layer.11.intermediate.dense.weight\n",
      "base_model.model.roberta.encoder.layer.11.intermediate.dense.bias\n",
      "base_model.model.roberta.encoder.layer.11.output.dense.weight\n",
      "base_model.model.roberta.encoder.layer.11.output.dense.bias\n",
      "base_model.model.roberta.encoder.layer.11.output.LayerNorm.weight\n",
      "base_model.model.roberta.encoder.layer.11.output.LayerNorm.bias\n",
      "base_model.model.roberta.pooler.dense.weight\n",
      "base_model.model.roberta.pooler.dense.bias\n",
      "base_model.model.classifier.original_module.weight\n",
      "base_model.model.classifier.original_module.bias\n",
      "base_model.model.classifier.modules_to_save.default.weight\n",
      "base_model.model.classifier.modules_to_save.default.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name == \"google/vit-base-patch16-224-in21k\"        \n",
    "from transformers import AutoModelForImageClassification\n",
    "model = AutoModelForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..', 'arch'))\n",
    "\n",
    "# Add to sys.path if not already present\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from lora import add_adapters_dataset\n",
    "\n",
    "model , output_layer_name, Lora_Config = add_adapters_dataset(model_name, model, 16, 16, lora_freeze_a=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.vit.embeddings.cls_token\n",
      "base_model.model.vit.embeddings.position_embeddings\n",
      "base_model.model.vit.embeddings.patch_embeddings.projection.weight\n",
      "base_model.model.vit.embeddings.patch_embeddings.projection.bias\n",
      "base_model.model.vit.encoder.layer.0.attention.attention.query.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.0.attention.attention.query.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.0.attention.attention.query.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.0.attention.attention.query.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.0.attention.attention.key.weight\n",
      "base_model.model.vit.encoder.layer.0.attention.attention.key.bias\n",
      "base_model.model.vit.encoder.layer.0.attention.attention.value.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.0.attention.attention.value.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.0.attention.attention.value.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.0.attention.attention.value.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.0.attention.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.0.attention.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.0.intermediate.dense.weight\n",
      "base_model.model.vit.encoder.layer.0.intermediate.dense.bias\n",
      "base_model.model.vit.encoder.layer.0.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.0.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.0.layernorm_before.weight\n",
      "base_model.model.vit.encoder.layer.0.layernorm_before.bias\n",
      "base_model.model.vit.encoder.layer.0.layernorm_after.weight\n",
      "base_model.model.vit.encoder.layer.0.layernorm_after.bias\n",
      "base_model.model.vit.encoder.layer.1.attention.attention.query.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.1.attention.attention.query.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.1.attention.attention.query.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.1.attention.attention.query.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.1.attention.attention.key.weight\n",
      "base_model.model.vit.encoder.layer.1.attention.attention.key.bias\n",
      "base_model.model.vit.encoder.layer.1.attention.attention.value.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.1.attention.attention.value.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.1.attention.attention.value.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.1.attention.attention.value.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.1.attention.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.1.attention.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.1.intermediate.dense.weight\n",
      "base_model.model.vit.encoder.layer.1.intermediate.dense.bias\n",
      "base_model.model.vit.encoder.layer.1.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.1.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.1.layernorm_before.weight\n",
      "base_model.model.vit.encoder.layer.1.layernorm_before.bias\n",
      "base_model.model.vit.encoder.layer.1.layernorm_after.weight\n",
      "base_model.model.vit.encoder.layer.1.layernorm_after.bias\n",
      "base_model.model.vit.encoder.layer.2.attention.attention.query.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.2.attention.attention.query.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.2.attention.attention.query.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.2.attention.attention.query.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.2.attention.attention.key.weight\n",
      "base_model.model.vit.encoder.layer.2.attention.attention.key.bias\n",
      "base_model.model.vit.encoder.layer.2.attention.attention.value.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.2.attention.attention.value.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.2.attention.attention.value.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.2.attention.attention.value.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.2.attention.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.2.attention.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.2.intermediate.dense.weight\n",
      "base_model.model.vit.encoder.layer.2.intermediate.dense.bias\n",
      "base_model.model.vit.encoder.layer.2.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.2.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.2.layernorm_before.weight\n",
      "base_model.model.vit.encoder.layer.2.layernorm_before.bias\n",
      "base_model.model.vit.encoder.layer.2.layernorm_after.weight\n",
      "base_model.model.vit.encoder.layer.2.layernorm_after.bias\n",
      "base_model.model.vit.encoder.layer.3.attention.attention.query.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.3.attention.attention.query.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.3.attention.attention.query.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.3.attention.attention.query.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.3.attention.attention.key.weight\n",
      "base_model.model.vit.encoder.layer.3.attention.attention.key.bias\n",
      "base_model.model.vit.encoder.layer.3.attention.attention.value.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.3.attention.attention.value.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.3.attention.attention.value.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.3.attention.attention.value.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.3.attention.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.3.attention.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.3.intermediate.dense.weight\n",
      "base_model.model.vit.encoder.layer.3.intermediate.dense.bias\n",
      "base_model.model.vit.encoder.layer.3.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.3.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.3.layernorm_before.weight\n",
      "base_model.model.vit.encoder.layer.3.layernorm_before.bias\n",
      "base_model.model.vit.encoder.layer.3.layernorm_after.weight\n",
      "base_model.model.vit.encoder.layer.3.layernorm_after.bias\n",
      "base_model.model.vit.encoder.layer.4.attention.attention.query.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.4.attention.attention.query.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.4.attention.attention.query.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.4.attention.attention.query.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.4.attention.attention.key.weight\n",
      "base_model.model.vit.encoder.layer.4.attention.attention.key.bias\n",
      "base_model.model.vit.encoder.layer.4.attention.attention.value.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.4.attention.attention.value.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.4.attention.attention.value.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.4.attention.attention.value.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.4.attention.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.4.attention.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.4.intermediate.dense.weight\n",
      "base_model.model.vit.encoder.layer.4.intermediate.dense.bias\n",
      "base_model.model.vit.encoder.layer.4.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.4.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.4.layernorm_before.weight\n",
      "base_model.model.vit.encoder.layer.4.layernorm_before.bias\n",
      "base_model.model.vit.encoder.layer.4.layernorm_after.weight\n",
      "base_model.model.vit.encoder.layer.4.layernorm_after.bias\n",
      "base_model.model.vit.encoder.layer.5.attention.attention.query.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.5.attention.attention.query.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.5.attention.attention.query.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.5.attention.attention.query.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.5.attention.attention.key.weight\n",
      "base_model.model.vit.encoder.layer.5.attention.attention.key.bias\n",
      "base_model.model.vit.encoder.layer.5.attention.attention.value.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.5.attention.attention.value.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.5.attention.attention.value.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.5.attention.attention.value.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.5.attention.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.5.attention.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.5.intermediate.dense.weight\n",
      "base_model.model.vit.encoder.layer.5.intermediate.dense.bias\n",
      "base_model.model.vit.encoder.layer.5.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.5.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.5.layernorm_before.weight\n",
      "base_model.model.vit.encoder.layer.5.layernorm_before.bias\n",
      "base_model.model.vit.encoder.layer.5.layernorm_after.weight\n",
      "base_model.model.vit.encoder.layer.5.layernorm_after.bias\n",
      "base_model.model.vit.encoder.layer.6.attention.attention.query.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.6.attention.attention.query.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.6.attention.attention.query.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.6.attention.attention.query.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.6.attention.attention.key.weight\n",
      "base_model.model.vit.encoder.layer.6.attention.attention.key.bias\n",
      "base_model.model.vit.encoder.layer.6.attention.attention.value.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.6.attention.attention.value.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.6.attention.attention.value.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.6.attention.attention.value.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.6.attention.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.6.attention.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.6.intermediate.dense.weight\n",
      "base_model.model.vit.encoder.layer.6.intermediate.dense.bias\n",
      "base_model.model.vit.encoder.layer.6.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.6.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.6.layernorm_before.weight\n",
      "base_model.model.vit.encoder.layer.6.layernorm_before.bias\n",
      "base_model.model.vit.encoder.layer.6.layernorm_after.weight\n",
      "base_model.model.vit.encoder.layer.6.layernorm_after.bias\n",
      "base_model.model.vit.encoder.layer.7.attention.attention.query.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.7.attention.attention.query.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.7.attention.attention.query.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.7.attention.attention.query.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.7.attention.attention.key.weight\n",
      "base_model.model.vit.encoder.layer.7.attention.attention.key.bias\n",
      "base_model.model.vit.encoder.layer.7.attention.attention.value.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.7.attention.attention.value.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.7.attention.attention.value.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.7.attention.attention.value.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.7.attention.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.7.attention.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.7.intermediate.dense.weight\n",
      "base_model.model.vit.encoder.layer.7.intermediate.dense.bias\n",
      "base_model.model.vit.encoder.layer.7.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.7.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.7.layernorm_before.weight\n",
      "base_model.model.vit.encoder.layer.7.layernorm_before.bias\n",
      "base_model.model.vit.encoder.layer.7.layernorm_after.weight\n",
      "base_model.model.vit.encoder.layer.7.layernorm_after.bias\n",
      "base_model.model.vit.encoder.layer.8.attention.attention.query.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.8.attention.attention.query.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.8.attention.attention.query.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.8.attention.attention.query.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.8.attention.attention.key.weight\n",
      "base_model.model.vit.encoder.layer.8.attention.attention.key.bias\n",
      "base_model.model.vit.encoder.layer.8.attention.attention.value.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.8.attention.attention.value.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.8.attention.attention.value.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.8.attention.attention.value.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.8.attention.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.8.attention.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.8.intermediate.dense.weight\n",
      "base_model.model.vit.encoder.layer.8.intermediate.dense.bias\n",
      "base_model.model.vit.encoder.layer.8.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.8.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.8.layernorm_before.weight\n",
      "base_model.model.vit.encoder.layer.8.layernorm_before.bias\n",
      "base_model.model.vit.encoder.layer.8.layernorm_after.weight\n",
      "base_model.model.vit.encoder.layer.8.layernorm_after.bias\n",
      "base_model.model.vit.encoder.layer.9.attention.attention.query.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.9.attention.attention.query.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.9.attention.attention.query.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.9.attention.attention.query.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.9.attention.attention.key.weight\n",
      "base_model.model.vit.encoder.layer.9.attention.attention.key.bias\n",
      "base_model.model.vit.encoder.layer.9.attention.attention.value.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.9.attention.attention.value.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.9.attention.attention.value.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.9.attention.attention.value.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.9.attention.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.9.attention.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.9.intermediate.dense.weight\n",
      "base_model.model.vit.encoder.layer.9.intermediate.dense.bias\n",
      "base_model.model.vit.encoder.layer.9.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.9.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.9.layernorm_before.weight\n",
      "base_model.model.vit.encoder.layer.9.layernorm_before.bias\n",
      "base_model.model.vit.encoder.layer.9.layernorm_after.weight\n",
      "base_model.model.vit.encoder.layer.9.layernorm_after.bias\n",
      "base_model.model.vit.encoder.layer.10.attention.attention.query.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.10.attention.attention.query.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.10.attention.attention.query.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.10.attention.attention.query.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.10.attention.attention.key.weight\n",
      "base_model.model.vit.encoder.layer.10.attention.attention.key.bias\n",
      "base_model.model.vit.encoder.layer.10.attention.attention.value.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.10.attention.attention.value.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.10.attention.attention.value.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.10.attention.attention.value.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.10.attention.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.10.attention.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.10.intermediate.dense.weight\n",
      "base_model.model.vit.encoder.layer.10.intermediate.dense.bias\n",
      "base_model.model.vit.encoder.layer.10.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.10.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.10.layernorm_before.weight\n",
      "base_model.model.vit.encoder.layer.10.layernorm_before.bias\n",
      "base_model.model.vit.encoder.layer.10.layernorm_after.weight\n",
      "base_model.model.vit.encoder.layer.10.layernorm_after.bias\n",
      "base_model.model.vit.encoder.layer.11.attention.attention.query.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.11.attention.attention.query.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.11.attention.attention.query.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.11.attention.attention.query.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.11.attention.attention.key.weight\n",
      "base_model.model.vit.encoder.layer.11.attention.attention.key.bias\n",
      "base_model.model.vit.encoder.layer.11.attention.attention.value.base_layer.weight\n",
      "base_model.model.vit.encoder.layer.11.attention.attention.value.base_layer.bias\n",
      "base_model.model.vit.encoder.layer.11.attention.attention.value.lora_A.default.weight\n",
      "base_model.model.vit.encoder.layer.11.attention.attention.value.lora_B.default.weight\n",
      "base_model.model.vit.encoder.layer.11.attention.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.11.attention.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.11.intermediate.dense.weight\n",
      "base_model.model.vit.encoder.layer.11.intermediate.dense.bias\n",
      "base_model.model.vit.encoder.layer.11.output.dense.weight\n",
      "base_model.model.vit.encoder.layer.11.output.dense.bias\n",
      "base_model.model.vit.encoder.layer.11.layernorm_before.weight\n",
      "base_model.model.vit.encoder.layer.11.layernorm_before.bias\n",
      "base_model.model.vit.encoder.layer.11.layernorm_after.weight\n",
      "base_model.model.vit.encoder.layer.11.layernorm_after.bias\n",
      "base_model.model.vit.layernorm.weight\n",
      "base_model.model.vit.layernorm.bias\n",
      "base_model.model.classifier.original_module.weight\n",
      "base_model.model.classifier.original_module.bias\n",
      "base_model.model.classifier.modules_to_save.default.weight\n",
      "base_model.model.classifier.modules_to_save.default.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "???\n",
      "A\n",
      "B\n",
      "torch.Size([16, 768]) torch.Size([768, 16])\n"
     ]
    }
   ],
   "source": [
    "base_name = \"base_model.model.vit.encoder.layer.0.attention.attention.value.base_layer.weight\"\n",
    "#base_name = \"base_model.model.roberta.encoder.layer.0.attention.self.value.weight\"\n",
    "def base_to_lora_name(base_name):\n",
    "    lora_A_name = base_name.replace(\"base_layer\", \"lora_A.default\")\n",
    "    lora_B_name = base_name.replace(\"base_layer\", \"lora_B.default\")\n",
    "    return lora_A_name, lora_B_name\n",
    "lora_A_name, lora_B_name = base_to_lora_name(base_name)\n",
    "\n",
    "#lora_A_name, lora_B_name = None, None\n",
    "for name, param in model.named_parameters():\n",
    "    if name == base_name:\n",
    "        print(\"???\")\n",
    "        base_param = param.clone()\n",
    "    if name == lora_A_name:\n",
    "        print(\"A\")\n",
    "        lora_A_param = param\n",
    "    if name == lora_B_name:\n",
    "        print('B')\n",
    "        lora_B_param = param\n",
    "print(lora_A_param.shape, lora_B_param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "lora_B_param.data = torch.randn_like(lora_B_param)\n",
    "\n",
    "scaling = 1\n",
    "my_product = scaling * lora_B_param @ lora_A_param\n",
    "merged_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vit.embeddings.cls_token\n",
      "vit.embeddings.position_embeddings\n",
      "vit.embeddings.patch_embeddings.projection.weight\n",
      "vit.embeddings.patch_embeddings.projection.bias\n",
      "vit.encoder.layer.0.attention.attention.query.weight\n",
      "vit.encoder.layer.0.attention.attention.query.bias\n",
      "vit.encoder.layer.0.attention.attention.key.weight\n",
      "vit.encoder.layer.0.attention.attention.key.bias\n",
      "vit.encoder.layer.0.attention.attention.value.weight\n",
      "vit.encoder.layer.0.attention.attention.value.bias\n",
      "vit.encoder.layer.0.attention.output.dense.weight\n",
      "vit.encoder.layer.0.attention.output.dense.bias\n",
      "vit.encoder.layer.0.intermediate.dense.weight\n",
      "vit.encoder.layer.0.intermediate.dense.bias\n",
      "vit.encoder.layer.0.output.dense.weight\n",
      "vit.encoder.layer.0.output.dense.bias\n",
      "vit.encoder.layer.0.layernorm_before.weight\n",
      "vit.encoder.layer.0.layernorm_before.bias\n",
      "vit.encoder.layer.0.layernorm_after.weight\n",
      "vit.encoder.layer.0.layernorm_after.bias\n",
      "vit.encoder.layer.1.attention.attention.query.weight\n",
      "vit.encoder.layer.1.attention.attention.query.bias\n",
      "vit.encoder.layer.1.attention.attention.key.weight\n",
      "vit.encoder.layer.1.attention.attention.key.bias\n",
      "vit.encoder.layer.1.attention.attention.value.weight\n",
      "vit.encoder.layer.1.attention.attention.value.bias\n",
      "vit.encoder.layer.1.attention.output.dense.weight\n",
      "vit.encoder.layer.1.attention.output.dense.bias\n",
      "vit.encoder.layer.1.intermediate.dense.weight\n",
      "vit.encoder.layer.1.intermediate.dense.bias\n",
      "vit.encoder.layer.1.output.dense.weight\n",
      "vit.encoder.layer.1.output.dense.bias\n",
      "vit.encoder.layer.1.layernorm_before.weight\n",
      "vit.encoder.layer.1.layernorm_before.bias\n",
      "vit.encoder.layer.1.layernorm_after.weight\n",
      "vit.encoder.layer.1.layernorm_after.bias\n",
      "vit.encoder.layer.2.attention.attention.query.weight\n",
      "vit.encoder.layer.2.attention.attention.query.bias\n",
      "vit.encoder.layer.2.attention.attention.key.weight\n",
      "vit.encoder.layer.2.attention.attention.key.bias\n",
      "vit.encoder.layer.2.attention.attention.value.weight\n",
      "vit.encoder.layer.2.attention.attention.value.bias\n",
      "vit.encoder.layer.2.attention.output.dense.weight\n",
      "vit.encoder.layer.2.attention.output.dense.bias\n",
      "vit.encoder.layer.2.intermediate.dense.weight\n",
      "vit.encoder.layer.2.intermediate.dense.bias\n",
      "vit.encoder.layer.2.output.dense.weight\n",
      "vit.encoder.layer.2.output.dense.bias\n",
      "vit.encoder.layer.2.layernorm_before.weight\n",
      "vit.encoder.layer.2.layernorm_before.bias\n",
      "vit.encoder.layer.2.layernorm_after.weight\n",
      "vit.encoder.layer.2.layernorm_after.bias\n",
      "vit.encoder.layer.3.attention.attention.query.weight\n",
      "vit.encoder.layer.3.attention.attention.query.bias\n",
      "vit.encoder.layer.3.attention.attention.key.weight\n",
      "vit.encoder.layer.3.attention.attention.key.bias\n",
      "vit.encoder.layer.3.attention.attention.value.weight\n",
      "vit.encoder.layer.3.attention.attention.value.bias\n",
      "vit.encoder.layer.3.attention.output.dense.weight\n",
      "vit.encoder.layer.3.attention.output.dense.bias\n",
      "vit.encoder.layer.3.intermediate.dense.weight\n",
      "vit.encoder.layer.3.intermediate.dense.bias\n",
      "vit.encoder.layer.3.output.dense.weight\n",
      "vit.encoder.layer.3.output.dense.bias\n",
      "vit.encoder.layer.3.layernorm_before.weight\n",
      "vit.encoder.layer.3.layernorm_before.bias\n",
      "vit.encoder.layer.3.layernorm_after.weight\n",
      "vit.encoder.layer.3.layernorm_after.bias\n",
      "vit.encoder.layer.4.attention.attention.query.weight\n",
      "vit.encoder.layer.4.attention.attention.query.bias\n",
      "vit.encoder.layer.4.attention.attention.key.weight\n",
      "vit.encoder.layer.4.attention.attention.key.bias\n",
      "vit.encoder.layer.4.attention.attention.value.weight\n",
      "vit.encoder.layer.4.attention.attention.value.bias\n",
      "vit.encoder.layer.4.attention.output.dense.weight\n",
      "vit.encoder.layer.4.attention.output.dense.bias\n",
      "vit.encoder.layer.4.intermediate.dense.weight\n",
      "vit.encoder.layer.4.intermediate.dense.bias\n",
      "vit.encoder.layer.4.output.dense.weight\n",
      "vit.encoder.layer.4.output.dense.bias\n",
      "vit.encoder.layer.4.layernorm_before.weight\n",
      "vit.encoder.layer.4.layernorm_before.bias\n",
      "vit.encoder.layer.4.layernorm_after.weight\n",
      "vit.encoder.layer.4.layernorm_after.bias\n",
      "vit.encoder.layer.5.attention.attention.query.weight\n",
      "vit.encoder.layer.5.attention.attention.query.bias\n",
      "vit.encoder.layer.5.attention.attention.key.weight\n",
      "vit.encoder.layer.5.attention.attention.key.bias\n",
      "vit.encoder.layer.5.attention.attention.value.weight\n",
      "vit.encoder.layer.5.attention.attention.value.bias\n",
      "vit.encoder.layer.5.attention.output.dense.weight\n",
      "vit.encoder.layer.5.attention.output.dense.bias\n",
      "vit.encoder.layer.5.intermediate.dense.weight\n",
      "vit.encoder.layer.5.intermediate.dense.bias\n",
      "vit.encoder.layer.5.output.dense.weight\n",
      "vit.encoder.layer.5.output.dense.bias\n",
      "vit.encoder.layer.5.layernorm_before.weight\n",
      "vit.encoder.layer.5.layernorm_before.bias\n",
      "vit.encoder.layer.5.layernorm_after.weight\n",
      "vit.encoder.layer.5.layernorm_after.bias\n",
      "vit.encoder.layer.6.attention.attention.query.weight\n",
      "vit.encoder.layer.6.attention.attention.query.bias\n",
      "vit.encoder.layer.6.attention.attention.key.weight\n",
      "vit.encoder.layer.6.attention.attention.key.bias\n",
      "vit.encoder.layer.6.attention.attention.value.weight\n",
      "vit.encoder.layer.6.attention.attention.value.bias\n",
      "vit.encoder.layer.6.attention.output.dense.weight\n",
      "vit.encoder.layer.6.attention.output.dense.bias\n",
      "vit.encoder.layer.6.intermediate.dense.weight\n",
      "vit.encoder.layer.6.intermediate.dense.bias\n",
      "vit.encoder.layer.6.output.dense.weight\n",
      "vit.encoder.layer.6.output.dense.bias\n",
      "vit.encoder.layer.6.layernorm_before.weight\n",
      "vit.encoder.layer.6.layernorm_before.bias\n",
      "vit.encoder.layer.6.layernorm_after.weight\n",
      "vit.encoder.layer.6.layernorm_after.bias\n",
      "vit.encoder.layer.7.attention.attention.query.weight\n",
      "vit.encoder.layer.7.attention.attention.query.bias\n",
      "vit.encoder.layer.7.attention.attention.key.weight\n",
      "vit.encoder.layer.7.attention.attention.key.bias\n",
      "vit.encoder.layer.7.attention.attention.value.weight\n",
      "vit.encoder.layer.7.attention.attention.value.bias\n",
      "vit.encoder.layer.7.attention.output.dense.weight\n",
      "vit.encoder.layer.7.attention.output.dense.bias\n",
      "vit.encoder.layer.7.intermediate.dense.weight\n",
      "vit.encoder.layer.7.intermediate.dense.bias\n",
      "vit.encoder.layer.7.output.dense.weight\n",
      "vit.encoder.layer.7.output.dense.bias\n",
      "vit.encoder.layer.7.layernorm_before.weight\n",
      "vit.encoder.layer.7.layernorm_before.bias\n",
      "vit.encoder.layer.7.layernorm_after.weight\n",
      "vit.encoder.layer.7.layernorm_after.bias\n",
      "vit.encoder.layer.8.attention.attention.query.weight\n",
      "vit.encoder.layer.8.attention.attention.query.bias\n",
      "vit.encoder.layer.8.attention.attention.key.weight\n",
      "vit.encoder.layer.8.attention.attention.key.bias\n",
      "vit.encoder.layer.8.attention.attention.value.weight\n",
      "vit.encoder.layer.8.attention.attention.value.bias\n",
      "vit.encoder.layer.8.attention.output.dense.weight\n",
      "vit.encoder.layer.8.attention.output.dense.bias\n",
      "vit.encoder.layer.8.intermediate.dense.weight\n",
      "vit.encoder.layer.8.intermediate.dense.bias\n",
      "vit.encoder.layer.8.output.dense.weight\n",
      "vit.encoder.layer.8.output.dense.bias\n",
      "vit.encoder.layer.8.layernorm_before.weight\n",
      "vit.encoder.layer.8.layernorm_before.bias\n",
      "vit.encoder.layer.8.layernorm_after.weight\n",
      "vit.encoder.layer.8.layernorm_after.bias\n",
      "vit.encoder.layer.9.attention.attention.query.weight\n",
      "vit.encoder.layer.9.attention.attention.query.bias\n",
      "vit.encoder.layer.9.attention.attention.key.weight\n",
      "vit.encoder.layer.9.attention.attention.key.bias\n",
      "vit.encoder.layer.9.attention.attention.value.weight\n",
      "vit.encoder.layer.9.attention.attention.value.bias\n",
      "vit.encoder.layer.9.attention.output.dense.weight\n",
      "vit.encoder.layer.9.attention.output.dense.bias\n",
      "vit.encoder.layer.9.intermediate.dense.weight\n",
      "vit.encoder.layer.9.intermediate.dense.bias\n",
      "vit.encoder.layer.9.output.dense.weight\n",
      "vit.encoder.layer.9.output.dense.bias\n",
      "vit.encoder.layer.9.layernorm_before.weight\n",
      "vit.encoder.layer.9.layernorm_before.bias\n",
      "vit.encoder.layer.9.layernorm_after.weight\n",
      "vit.encoder.layer.9.layernorm_after.bias\n",
      "vit.encoder.layer.10.attention.attention.query.weight\n",
      "vit.encoder.layer.10.attention.attention.query.bias\n",
      "vit.encoder.layer.10.attention.attention.key.weight\n",
      "vit.encoder.layer.10.attention.attention.key.bias\n",
      "vit.encoder.layer.10.attention.attention.value.weight\n",
      "vit.encoder.layer.10.attention.attention.value.bias\n",
      "vit.encoder.layer.10.attention.output.dense.weight\n",
      "vit.encoder.layer.10.attention.output.dense.bias\n",
      "vit.encoder.layer.10.intermediate.dense.weight\n",
      "vit.encoder.layer.10.intermediate.dense.bias\n",
      "vit.encoder.layer.10.output.dense.weight\n",
      "vit.encoder.layer.10.output.dense.bias\n",
      "vit.encoder.layer.10.layernorm_before.weight\n",
      "vit.encoder.layer.10.layernorm_before.bias\n",
      "vit.encoder.layer.10.layernorm_after.weight\n",
      "vit.encoder.layer.10.layernorm_after.bias\n",
      "vit.encoder.layer.11.attention.attention.query.weight\n",
      "vit.encoder.layer.11.attention.attention.query.bias\n",
      "vit.encoder.layer.11.attention.attention.key.weight\n",
      "vit.encoder.layer.11.attention.attention.key.bias\n",
      "vit.encoder.layer.11.attention.attention.value.weight\n",
      "vit.encoder.layer.11.attention.attention.value.bias\n",
      "vit.encoder.layer.11.attention.output.dense.weight\n",
      "vit.encoder.layer.11.attention.output.dense.bias\n",
      "vit.encoder.layer.11.intermediate.dense.weight\n",
      "vit.encoder.layer.11.intermediate.dense.bias\n",
      "vit.encoder.layer.11.output.dense.weight\n",
      "vit.encoder.layer.11.output.dense.bias\n",
      "vit.encoder.layer.11.layernorm_before.weight\n",
      "vit.encoder.layer.11.layernorm_before.bias\n",
      "vit.encoder.layer.11.layernorm_after.weight\n",
      "vit.encoder.layer.11.layernorm_after.bias\n",
      "vit.layernorm.weight\n",
      "vit.layernorm.bias\n",
      "classifier.weight\n",
      "classifier.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in merged_model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_base_name = \"vit.encoder.layer.0.attention.attention.value.weight\"\n",
    "for name, param in merged_model.named_parameters():\n",
    "    if name == merged_base_name:\n",
    "        real_update = param - base_param\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0321,  0.0991, -0.1132,  ..., -0.1183,  0.1426, -0.1396],\n",
      "        [ 0.0086, -0.0049,  0.0900,  ...,  0.1232, -0.0167, -0.0734],\n",
      "        [-0.0950, -0.0079,  0.0176,  ...,  0.0036, -0.0152,  0.1182],\n",
      "        ...,\n",
      "        [ 0.0895, -0.1026,  0.0633,  ...,  0.0311, -0.0354,  0.0450],\n",
      "        [ 0.1237, -0.0355, -0.0320,  ..., -0.0396,  0.0303,  0.0164],\n",
      "        [ 0.1022, -0.1361,  0.0503,  ...,  0.1041, -0.0256,  0.0526]])\n"
     ]
    }
   ],
   "source": [
    "print(real_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0321,  0.0991, -0.1132,  ..., -0.1183,  0.1426, -0.1396],\n",
      "        [ 0.0086, -0.0049,  0.0900,  ...,  0.1232, -0.0167, -0.0734],\n",
      "        [-0.0950, -0.0079,  0.0176,  ...,  0.0036, -0.0152,  0.1182],\n",
      "        ...,\n",
      "        [ 0.0895, -0.1026,  0.0633,  ...,  0.0311, -0.0354,  0.0450],\n",
      "        [ 0.1237, -0.0355, -0.0320,  ..., -0.0396,  0.0303,  0.0164],\n",
      "        [ 0.1022, -0.1361,  0.0503,  ...,  0.1041, -0.0256,  0.0526]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(my_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model_name = \"gpt2\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels=20,pad_token_id=50256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/lucmon/lucmon/anaconda3/envs/mlopt/lib/python3.11/site-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..', 'arch'))\n",
    "\n",
    "# Add to sys.path if not already present\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from lora import add_adapters_dataset\n",
    "\n",
    "model , output_layer_name, Lora_Config = add_adapters_dataset(model_name, model, 16, 16, lora_freeze_a=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.transformer.wte.weight torch.Size([50257, 768])\n",
      "base_model.model.transformer.wpe.weight torch.Size([1024, 768])\n",
      "base_model.model.transformer.h.0.ln_1.weight torch.Size([768])\n",
      "base_model.model.transformer.h.0.ln_1.bias torch.Size([768])\n",
      "base_model.model.transformer.h.0.attn.c_attn.base_layer.weight torch.Size([768, 2304])\n",
      "base_model.model.transformer.h.0.attn.c_attn.base_layer.bias torch.Size([2304])\n",
      "base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight torch.Size([2304, 16])\n",
      "base_model.model.transformer.h.0.attn.c_proj.base_layer.weight torch.Size([768, 768])\n",
      "base_model.model.transformer.h.0.attn.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.0.ln_2.weight torch.Size([768])\n",
      "base_model.model.transformer.h.0.ln_2.bias torch.Size([768])\n",
      "base_model.model.transformer.h.0.mlp.c_fc.base_layer.weight torch.Size([768, 3072])\n",
      "base_model.model.transformer.h.0.mlp.c_fc.base_layer.bias torch.Size([3072])\n",
      "base_model.model.transformer.h.0.mlp.c_fc.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.0.mlp.c_fc.lora_B.default.weight torch.Size([3072, 16])\n",
      "base_model.model.transformer.h.0.mlp.c_proj.base_layer.weight torch.Size([3072, 768])\n",
      "base_model.model.transformer.h.0.mlp.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.0.mlp.c_proj.lora_A.default.weight torch.Size([16, 3072])\n",
      "base_model.model.transformer.h.0.mlp.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.1.ln_1.weight torch.Size([768])\n",
      "base_model.model.transformer.h.1.ln_1.bias torch.Size([768])\n",
      "base_model.model.transformer.h.1.attn.c_attn.base_layer.weight torch.Size([768, 2304])\n",
      "base_model.model.transformer.h.1.attn.c_attn.base_layer.bias torch.Size([2304])\n",
      "base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight torch.Size([2304, 16])\n",
      "base_model.model.transformer.h.1.attn.c_proj.base_layer.weight torch.Size([768, 768])\n",
      "base_model.model.transformer.h.1.attn.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.1.ln_2.weight torch.Size([768])\n",
      "base_model.model.transformer.h.1.ln_2.bias torch.Size([768])\n",
      "base_model.model.transformer.h.1.mlp.c_fc.base_layer.weight torch.Size([768, 3072])\n",
      "base_model.model.transformer.h.1.mlp.c_fc.base_layer.bias torch.Size([3072])\n",
      "base_model.model.transformer.h.1.mlp.c_fc.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.1.mlp.c_fc.lora_B.default.weight torch.Size([3072, 16])\n",
      "base_model.model.transformer.h.1.mlp.c_proj.base_layer.weight torch.Size([3072, 768])\n",
      "base_model.model.transformer.h.1.mlp.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.1.mlp.c_proj.lora_A.default.weight torch.Size([16, 3072])\n",
      "base_model.model.transformer.h.1.mlp.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.2.ln_1.weight torch.Size([768])\n",
      "base_model.model.transformer.h.2.ln_1.bias torch.Size([768])\n",
      "base_model.model.transformer.h.2.attn.c_attn.base_layer.weight torch.Size([768, 2304])\n",
      "base_model.model.transformer.h.2.attn.c_attn.base_layer.bias torch.Size([2304])\n",
      "base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight torch.Size([2304, 16])\n",
      "base_model.model.transformer.h.2.attn.c_proj.base_layer.weight torch.Size([768, 768])\n",
      "base_model.model.transformer.h.2.attn.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.2.ln_2.weight torch.Size([768])\n",
      "base_model.model.transformer.h.2.ln_2.bias torch.Size([768])\n",
      "base_model.model.transformer.h.2.mlp.c_fc.base_layer.weight torch.Size([768, 3072])\n",
      "base_model.model.transformer.h.2.mlp.c_fc.base_layer.bias torch.Size([3072])\n",
      "base_model.model.transformer.h.2.mlp.c_fc.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.2.mlp.c_fc.lora_B.default.weight torch.Size([3072, 16])\n",
      "base_model.model.transformer.h.2.mlp.c_proj.base_layer.weight torch.Size([3072, 768])\n",
      "base_model.model.transformer.h.2.mlp.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.2.mlp.c_proj.lora_A.default.weight torch.Size([16, 3072])\n",
      "base_model.model.transformer.h.2.mlp.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.3.ln_1.weight torch.Size([768])\n",
      "base_model.model.transformer.h.3.ln_1.bias torch.Size([768])\n",
      "base_model.model.transformer.h.3.attn.c_attn.base_layer.weight torch.Size([768, 2304])\n",
      "base_model.model.transformer.h.3.attn.c_attn.base_layer.bias torch.Size([2304])\n",
      "base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight torch.Size([2304, 16])\n",
      "base_model.model.transformer.h.3.attn.c_proj.base_layer.weight torch.Size([768, 768])\n",
      "base_model.model.transformer.h.3.attn.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.3.attn.c_proj.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.3.attn.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.3.ln_2.weight torch.Size([768])\n",
      "base_model.model.transformer.h.3.ln_2.bias torch.Size([768])\n",
      "base_model.model.transformer.h.3.mlp.c_fc.base_layer.weight torch.Size([768, 3072])\n",
      "base_model.model.transformer.h.3.mlp.c_fc.base_layer.bias torch.Size([3072])\n",
      "base_model.model.transformer.h.3.mlp.c_fc.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.3.mlp.c_fc.lora_B.default.weight torch.Size([3072, 16])\n",
      "base_model.model.transformer.h.3.mlp.c_proj.base_layer.weight torch.Size([3072, 768])\n",
      "base_model.model.transformer.h.3.mlp.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.3.mlp.c_proj.lora_A.default.weight torch.Size([16, 3072])\n",
      "base_model.model.transformer.h.3.mlp.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.4.ln_1.weight torch.Size([768])\n",
      "base_model.model.transformer.h.4.ln_1.bias torch.Size([768])\n",
      "base_model.model.transformer.h.4.attn.c_attn.base_layer.weight torch.Size([768, 2304])\n",
      "base_model.model.transformer.h.4.attn.c_attn.base_layer.bias torch.Size([2304])\n",
      "base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight torch.Size([2304, 16])\n",
      "base_model.model.transformer.h.4.attn.c_proj.base_layer.weight torch.Size([768, 768])\n",
      "base_model.model.transformer.h.4.attn.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.4.attn.c_proj.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.4.attn.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.4.ln_2.weight torch.Size([768])\n",
      "base_model.model.transformer.h.4.ln_2.bias torch.Size([768])\n",
      "base_model.model.transformer.h.4.mlp.c_fc.base_layer.weight torch.Size([768, 3072])\n",
      "base_model.model.transformer.h.4.mlp.c_fc.base_layer.bias torch.Size([3072])\n",
      "base_model.model.transformer.h.4.mlp.c_fc.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.4.mlp.c_fc.lora_B.default.weight torch.Size([3072, 16])\n",
      "base_model.model.transformer.h.4.mlp.c_proj.base_layer.weight torch.Size([3072, 768])\n",
      "base_model.model.transformer.h.4.mlp.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.4.mlp.c_proj.lora_A.default.weight torch.Size([16, 3072])\n",
      "base_model.model.transformer.h.4.mlp.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.5.ln_1.weight torch.Size([768])\n",
      "base_model.model.transformer.h.5.ln_1.bias torch.Size([768])\n",
      "base_model.model.transformer.h.5.attn.c_attn.base_layer.weight torch.Size([768, 2304])\n",
      "base_model.model.transformer.h.5.attn.c_attn.base_layer.bias torch.Size([2304])\n",
      "base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight torch.Size([2304, 16])\n",
      "base_model.model.transformer.h.5.attn.c_proj.base_layer.weight torch.Size([768, 768])\n",
      "base_model.model.transformer.h.5.attn.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.5.attn.c_proj.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.5.attn.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.5.ln_2.weight torch.Size([768])\n",
      "base_model.model.transformer.h.5.ln_2.bias torch.Size([768])\n",
      "base_model.model.transformer.h.5.mlp.c_fc.base_layer.weight torch.Size([768, 3072])\n",
      "base_model.model.transformer.h.5.mlp.c_fc.base_layer.bias torch.Size([3072])\n",
      "base_model.model.transformer.h.5.mlp.c_fc.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.5.mlp.c_fc.lora_B.default.weight torch.Size([3072, 16])\n",
      "base_model.model.transformer.h.5.mlp.c_proj.base_layer.weight torch.Size([3072, 768])\n",
      "base_model.model.transformer.h.5.mlp.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.5.mlp.c_proj.lora_A.default.weight torch.Size([16, 3072])\n",
      "base_model.model.transformer.h.5.mlp.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.6.ln_1.weight torch.Size([768])\n",
      "base_model.model.transformer.h.6.ln_1.bias torch.Size([768])\n",
      "base_model.model.transformer.h.6.attn.c_attn.base_layer.weight torch.Size([768, 2304])\n",
      "base_model.model.transformer.h.6.attn.c_attn.base_layer.bias torch.Size([2304])\n",
      "base_model.model.transformer.h.6.attn.c_attn.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.6.attn.c_attn.lora_B.default.weight torch.Size([2304, 16])\n",
      "base_model.model.transformer.h.6.attn.c_proj.base_layer.weight torch.Size([768, 768])\n",
      "base_model.model.transformer.h.6.attn.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.6.attn.c_proj.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.6.attn.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.6.ln_2.weight torch.Size([768])\n",
      "base_model.model.transformer.h.6.ln_2.bias torch.Size([768])\n",
      "base_model.model.transformer.h.6.mlp.c_fc.base_layer.weight torch.Size([768, 3072])\n",
      "base_model.model.transformer.h.6.mlp.c_fc.base_layer.bias torch.Size([3072])\n",
      "base_model.model.transformer.h.6.mlp.c_fc.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.6.mlp.c_fc.lora_B.default.weight torch.Size([3072, 16])\n",
      "base_model.model.transformer.h.6.mlp.c_proj.base_layer.weight torch.Size([3072, 768])\n",
      "base_model.model.transformer.h.6.mlp.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.6.mlp.c_proj.lora_A.default.weight torch.Size([16, 3072])\n",
      "base_model.model.transformer.h.6.mlp.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.7.ln_1.weight torch.Size([768])\n",
      "base_model.model.transformer.h.7.ln_1.bias torch.Size([768])\n",
      "base_model.model.transformer.h.7.attn.c_attn.base_layer.weight torch.Size([768, 2304])\n",
      "base_model.model.transformer.h.7.attn.c_attn.base_layer.bias torch.Size([2304])\n",
      "base_model.model.transformer.h.7.attn.c_attn.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.7.attn.c_attn.lora_B.default.weight torch.Size([2304, 16])\n",
      "base_model.model.transformer.h.7.attn.c_proj.base_layer.weight torch.Size([768, 768])\n",
      "base_model.model.transformer.h.7.attn.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.7.attn.c_proj.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.7.attn.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.7.ln_2.weight torch.Size([768])\n",
      "base_model.model.transformer.h.7.ln_2.bias torch.Size([768])\n",
      "base_model.model.transformer.h.7.mlp.c_fc.base_layer.weight torch.Size([768, 3072])\n",
      "base_model.model.transformer.h.7.mlp.c_fc.base_layer.bias torch.Size([3072])\n",
      "base_model.model.transformer.h.7.mlp.c_fc.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.7.mlp.c_fc.lora_B.default.weight torch.Size([3072, 16])\n",
      "base_model.model.transformer.h.7.mlp.c_proj.base_layer.weight torch.Size([3072, 768])\n",
      "base_model.model.transformer.h.7.mlp.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.7.mlp.c_proj.lora_A.default.weight torch.Size([16, 3072])\n",
      "base_model.model.transformer.h.7.mlp.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.8.ln_1.weight torch.Size([768])\n",
      "base_model.model.transformer.h.8.ln_1.bias torch.Size([768])\n",
      "base_model.model.transformer.h.8.attn.c_attn.base_layer.weight torch.Size([768, 2304])\n",
      "base_model.model.transformer.h.8.attn.c_attn.base_layer.bias torch.Size([2304])\n",
      "base_model.model.transformer.h.8.attn.c_attn.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.8.attn.c_attn.lora_B.default.weight torch.Size([2304, 16])\n",
      "base_model.model.transformer.h.8.attn.c_proj.base_layer.weight torch.Size([768, 768])\n",
      "base_model.model.transformer.h.8.attn.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.8.attn.c_proj.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.8.attn.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.8.ln_2.weight torch.Size([768])\n",
      "base_model.model.transformer.h.8.ln_2.bias torch.Size([768])\n",
      "base_model.model.transformer.h.8.mlp.c_fc.base_layer.weight torch.Size([768, 3072])\n",
      "base_model.model.transformer.h.8.mlp.c_fc.base_layer.bias torch.Size([3072])\n",
      "base_model.model.transformer.h.8.mlp.c_fc.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.8.mlp.c_fc.lora_B.default.weight torch.Size([3072, 16])\n",
      "base_model.model.transformer.h.8.mlp.c_proj.base_layer.weight torch.Size([3072, 768])\n",
      "base_model.model.transformer.h.8.mlp.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.8.mlp.c_proj.lora_A.default.weight torch.Size([16, 3072])\n",
      "base_model.model.transformer.h.8.mlp.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.9.ln_1.weight torch.Size([768])\n",
      "base_model.model.transformer.h.9.ln_1.bias torch.Size([768])\n",
      "base_model.model.transformer.h.9.attn.c_attn.base_layer.weight torch.Size([768, 2304])\n",
      "base_model.model.transformer.h.9.attn.c_attn.base_layer.bias torch.Size([2304])\n",
      "base_model.model.transformer.h.9.attn.c_attn.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.9.attn.c_attn.lora_B.default.weight torch.Size([2304, 16])\n",
      "base_model.model.transformer.h.9.attn.c_proj.base_layer.weight torch.Size([768, 768])\n",
      "base_model.model.transformer.h.9.attn.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.9.attn.c_proj.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.9.attn.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.9.ln_2.weight torch.Size([768])\n",
      "base_model.model.transformer.h.9.ln_2.bias torch.Size([768])\n",
      "base_model.model.transformer.h.9.mlp.c_fc.base_layer.weight torch.Size([768, 3072])\n",
      "base_model.model.transformer.h.9.mlp.c_fc.base_layer.bias torch.Size([3072])\n",
      "base_model.model.transformer.h.9.mlp.c_fc.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.9.mlp.c_fc.lora_B.default.weight torch.Size([3072, 16])\n",
      "base_model.model.transformer.h.9.mlp.c_proj.base_layer.weight torch.Size([3072, 768])\n",
      "base_model.model.transformer.h.9.mlp.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.9.mlp.c_proj.lora_A.default.weight torch.Size([16, 3072])\n",
      "base_model.model.transformer.h.9.mlp.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.10.ln_1.weight torch.Size([768])\n",
      "base_model.model.transformer.h.10.ln_1.bias torch.Size([768])\n",
      "base_model.model.transformer.h.10.attn.c_attn.base_layer.weight torch.Size([768, 2304])\n",
      "base_model.model.transformer.h.10.attn.c_attn.base_layer.bias torch.Size([2304])\n",
      "base_model.model.transformer.h.10.attn.c_attn.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.10.attn.c_attn.lora_B.default.weight torch.Size([2304, 16])\n",
      "base_model.model.transformer.h.10.attn.c_proj.base_layer.weight torch.Size([768, 768])\n",
      "base_model.model.transformer.h.10.attn.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.10.attn.c_proj.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.10.attn.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.10.ln_2.weight torch.Size([768])\n",
      "base_model.model.transformer.h.10.ln_2.bias torch.Size([768])\n",
      "base_model.model.transformer.h.10.mlp.c_fc.base_layer.weight torch.Size([768, 3072])\n",
      "base_model.model.transformer.h.10.mlp.c_fc.base_layer.bias torch.Size([3072])\n",
      "base_model.model.transformer.h.10.mlp.c_fc.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.10.mlp.c_fc.lora_B.default.weight torch.Size([3072, 16])\n",
      "base_model.model.transformer.h.10.mlp.c_proj.base_layer.weight torch.Size([3072, 768])\n",
      "base_model.model.transformer.h.10.mlp.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.10.mlp.c_proj.lora_A.default.weight torch.Size([16, 3072])\n",
      "base_model.model.transformer.h.10.mlp.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.11.ln_1.weight torch.Size([768])\n",
      "base_model.model.transformer.h.11.ln_1.bias torch.Size([768])\n",
      "base_model.model.transformer.h.11.attn.c_attn.base_layer.weight torch.Size([768, 2304])\n",
      "base_model.model.transformer.h.11.attn.c_attn.base_layer.bias torch.Size([2304])\n",
      "base_model.model.transformer.h.11.attn.c_attn.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.11.attn.c_attn.lora_B.default.weight torch.Size([2304, 16])\n",
      "base_model.model.transformer.h.11.attn.c_proj.base_layer.weight torch.Size([768, 768])\n",
      "base_model.model.transformer.h.11.attn.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.11.attn.c_proj.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.11.attn.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.h.11.ln_2.weight torch.Size([768])\n",
      "base_model.model.transformer.h.11.ln_2.bias torch.Size([768])\n",
      "base_model.model.transformer.h.11.mlp.c_fc.base_layer.weight torch.Size([768, 3072])\n",
      "base_model.model.transformer.h.11.mlp.c_fc.base_layer.bias torch.Size([3072])\n",
      "base_model.model.transformer.h.11.mlp.c_fc.lora_A.default.weight torch.Size([16, 768])\n",
      "base_model.model.transformer.h.11.mlp.c_fc.lora_B.default.weight torch.Size([3072, 16])\n",
      "base_model.model.transformer.h.11.mlp.c_proj.base_layer.weight torch.Size([3072, 768])\n",
      "base_model.model.transformer.h.11.mlp.c_proj.base_layer.bias torch.Size([768])\n",
      "base_model.model.transformer.h.11.mlp.c_proj.lora_A.default.weight torch.Size([16, 3072])\n",
      "base_model.model.transformer.h.11.mlp.c_proj.lora_B.default.weight torch.Size([768, 16])\n",
      "base_model.model.transformer.ln_f.weight torch.Size([768])\n",
      "base_model.model.transformer.ln_f.bias torch.Size([768])\n",
      "base_model.model.score.original_module.weight torch.Size([20, 768])\n",
      "base_model.model.score.modules_to_save.default.weight torch.Size([20, 768])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "???\n",
      "A\n",
      "B\n",
      "torch.Size([16, 768]) torch.Size([2304, 16])\n"
     ]
    }
   ],
   "source": [
    "base_name = \"base_model.model.transformer.h.0.attn.c_attn.base_layer.weight\"\n",
    "#base_name = \"base_model.model.roberta.encoder.layer.0.attention.self.value.weight\"\n",
    "def base_to_lora_name(base_name):\n",
    "    lora_A_name = base_name.replace(\"base_layer\", \"lora_A.default\")\n",
    "    lora_B_name = base_name.replace(\"base_layer\", \"lora_B.default\")\n",
    "    return lora_A_name, lora_B_name\n",
    "lora_A_name, lora_B_name = base_to_lora_name(base_name)\n",
    "\n",
    "#lora_A_name, lora_B_name = None, None\n",
    "for name, param in model.named_parameters():\n",
    "    if name == base_name:\n",
    "        print(\"???\")\n",
    "        base_param = param.clone()\n",
    "    if name == lora_A_name:\n",
    "        print(\"A\")\n",
    "        lora_A_param = param\n",
    "    if name == lora_B_name:\n",
    "        print('B')\n",
    "        lora_B_param = param\n",
    "print(lora_A_param.shape, lora_B_param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "lora_B_param.data = torch.randn_like(lora_B_param)\n",
    "\n",
    "scaling = 1\n",
    "my_product = scaling * lora_B_param @ lora_A_param\n",
    "merged_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "transformer.wpe.weight\n",
      "transformer.h.0.ln_1.weight\n",
      "transformer.h.0.ln_1.bias\n",
      "transformer.h.0.attn.c_attn.weight\n",
      "transformer.h.0.attn.c_attn.bias\n",
      "transformer.h.0.attn.c_proj.weight\n",
      "transformer.h.0.attn.c_proj.bias\n",
      "transformer.h.0.ln_2.weight\n",
      "transformer.h.0.ln_2.bias\n",
      "transformer.h.0.mlp.c_fc.weight\n",
      "transformer.h.0.mlp.c_fc.bias\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "transformer.h.0.mlp.c_proj.bias\n",
      "transformer.h.1.ln_1.weight\n",
      "transformer.h.1.ln_1.bias\n",
      "transformer.h.1.attn.c_attn.weight\n",
      "transformer.h.1.attn.c_attn.bias\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "transformer.h.1.attn.c_proj.bias\n",
      "transformer.h.1.ln_2.weight\n",
      "transformer.h.1.ln_2.bias\n",
      "transformer.h.1.mlp.c_fc.weight\n",
      "transformer.h.1.mlp.c_fc.bias\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "transformer.h.1.mlp.c_proj.bias\n",
      "transformer.h.2.ln_1.weight\n",
      "transformer.h.2.ln_1.bias\n",
      "transformer.h.2.attn.c_attn.weight\n",
      "transformer.h.2.attn.c_attn.bias\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "transformer.h.2.attn.c_proj.bias\n",
      "transformer.h.2.ln_2.weight\n",
      "transformer.h.2.ln_2.bias\n",
      "transformer.h.2.mlp.c_fc.weight\n",
      "transformer.h.2.mlp.c_fc.bias\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "transformer.h.2.mlp.c_proj.bias\n",
      "transformer.h.3.ln_1.weight\n",
      "transformer.h.3.ln_1.bias\n",
      "transformer.h.3.attn.c_attn.weight\n",
      "transformer.h.3.attn.c_attn.bias\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "transformer.h.3.attn.c_proj.bias\n",
      "transformer.h.3.ln_2.weight\n",
      "transformer.h.3.ln_2.bias\n",
      "transformer.h.3.mlp.c_fc.weight\n",
      "transformer.h.3.mlp.c_fc.bias\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "transformer.h.3.mlp.c_proj.bias\n",
      "transformer.h.4.ln_1.weight\n",
      "transformer.h.4.ln_1.bias\n",
      "transformer.h.4.attn.c_attn.weight\n",
      "transformer.h.4.attn.c_attn.bias\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "transformer.h.4.attn.c_proj.bias\n",
      "transformer.h.4.ln_2.weight\n",
      "transformer.h.4.ln_2.bias\n",
      "transformer.h.4.mlp.c_fc.weight\n",
      "transformer.h.4.mlp.c_fc.bias\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "transformer.h.4.mlp.c_proj.bias\n",
      "transformer.h.5.ln_1.weight\n",
      "transformer.h.5.ln_1.bias\n",
      "transformer.h.5.attn.c_attn.weight\n",
      "transformer.h.5.attn.c_attn.bias\n",
      "transformer.h.5.attn.c_proj.weight\n",
      "transformer.h.5.attn.c_proj.bias\n",
      "transformer.h.5.ln_2.weight\n",
      "transformer.h.5.ln_2.bias\n",
      "transformer.h.5.mlp.c_fc.weight\n",
      "transformer.h.5.mlp.c_fc.bias\n",
      "transformer.h.5.mlp.c_proj.weight\n",
      "transformer.h.5.mlp.c_proj.bias\n",
      "transformer.h.6.ln_1.weight\n",
      "transformer.h.6.ln_1.bias\n",
      "transformer.h.6.attn.c_attn.weight\n",
      "transformer.h.6.attn.c_attn.bias\n",
      "transformer.h.6.attn.c_proj.weight\n",
      "transformer.h.6.attn.c_proj.bias\n",
      "transformer.h.6.ln_2.weight\n",
      "transformer.h.6.ln_2.bias\n",
      "transformer.h.6.mlp.c_fc.weight\n",
      "transformer.h.6.mlp.c_fc.bias\n",
      "transformer.h.6.mlp.c_proj.weight\n",
      "transformer.h.6.mlp.c_proj.bias\n",
      "transformer.h.7.ln_1.weight\n",
      "transformer.h.7.ln_1.bias\n",
      "transformer.h.7.attn.c_attn.weight\n",
      "transformer.h.7.attn.c_attn.bias\n",
      "transformer.h.7.attn.c_proj.weight\n",
      "transformer.h.7.attn.c_proj.bias\n",
      "transformer.h.7.ln_2.weight\n",
      "transformer.h.7.ln_2.bias\n",
      "transformer.h.7.mlp.c_fc.weight\n",
      "transformer.h.7.mlp.c_fc.bias\n",
      "transformer.h.7.mlp.c_proj.weight\n",
      "transformer.h.7.mlp.c_proj.bias\n",
      "transformer.h.8.ln_1.weight\n",
      "transformer.h.8.ln_1.bias\n",
      "transformer.h.8.attn.c_attn.weight\n",
      "transformer.h.8.attn.c_attn.bias\n",
      "transformer.h.8.attn.c_proj.weight\n",
      "transformer.h.8.attn.c_proj.bias\n",
      "transformer.h.8.ln_2.weight\n",
      "transformer.h.8.ln_2.bias\n",
      "transformer.h.8.mlp.c_fc.weight\n",
      "transformer.h.8.mlp.c_fc.bias\n",
      "transformer.h.8.mlp.c_proj.weight\n",
      "transformer.h.8.mlp.c_proj.bias\n",
      "transformer.h.9.ln_1.weight\n",
      "transformer.h.9.ln_1.bias\n",
      "transformer.h.9.attn.c_attn.weight\n",
      "transformer.h.9.attn.c_attn.bias\n",
      "transformer.h.9.attn.c_proj.weight\n",
      "transformer.h.9.attn.c_proj.bias\n",
      "transformer.h.9.ln_2.weight\n",
      "transformer.h.9.ln_2.bias\n",
      "transformer.h.9.mlp.c_fc.weight\n",
      "transformer.h.9.mlp.c_fc.bias\n",
      "transformer.h.9.mlp.c_proj.weight\n",
      "transformer.h.9.mlp.c_proj.bias\n",
      "transformer.h.10.ln_1.weight\n",
      "transformer.h.10.ln_1.bias\n",
      "transformer.h.10.attn.c_attn.weight\n",
      "transformer.h.10.attn.c_attn.bias\n",
      "transformer.h.10.attn.c_proj.weight\n",
      "transformer.h.10.attn.c_proj.bias\n",
      "transformer.h.10.ln_2.weight\n",
      "transformer.h.10.ln_2.bias\n",
      "transformer.h.10.mlp.c_fc.weight\n",
      "transformer.h.10.mlp.c_fc.bias\n",
      "transformer.h.10.mlp.c_proj.weight\n",
      "transformer.h.10.mlp.c_proj.bias\n",
      "transformer.h.11.ln_1.weight\n",
      "transformer.h.11.ln_1.bias\n",
      "transformer.h.11.attn.c_attn.weight\n",
      "transformer.h.11.attn.c_attn.bias\n",
      "transformer.h.11.attn.c_proj.weight\n",
      "transformer.h.11.attn.c_proj.bias\n",
      "transformer.h.11.ln_2.weight\n",
      "transformer.h.11.ln_2.bias\n",
      "transformer.h.11.mlp.c_fc.weight\n",
      "transformer.h.11.mlp.c_fc.bias\n",
      "transformer.h.11.mlp.c_proj.weight\n",
      "transformer.h.11.mlp.c_proj.bias\n",
      "transformer.ln_f.weight\n",
      "transformer.ln_f.bias\n",
      "score.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in merged_model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_base_name = \"transformer.h.0.attn.c_attn.weight\"\n",
    "for name, param in merged_model.named_parameters():\n",
    "    if name == merged_base_name:\n",
    "        real_update = param - base_param\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0546, -0.0664,  0.0471,  ...,  0.1405,  0.0787,  0.0821],\n",
      "        [ 0.1177, -0.0407,  0.0580,  ...,  0.0716, -0.0565, -0.0031],\n",
      "        [-0.0689, -0.0574, -0.0427,  ...,  0.0564, -0.0220,  0.0140],\n",
      "        ...,\n",
      "        [ 0.1406,  0.1481,  0.0080,  ...,  0.0284,  0.0265,  0.0121],\n",
      "        [ 0.0258,  0.0373, -0.0037,  ...,  0.0410,  0.0567, -0.0127],\n",
      "        [-0.1159, -0.0073,  0.0870,  ...,  0.0939,  0.0538,  0.0147]])\n",
      "torch.Size([768, 2304])\n"
     ]
    }
   ],
   "source": [
    "print(real_update)\n",
    "print(real_update.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0546,  0.1177, -0.0689,  ...,  0.1406,  0.0258, -0.1159],\n",
      "        [-0.0664, -0.0407, -0.0574,  ...,  0.1481,  0.0373, -0.0073],\n",
      "        [ 0.0471,  0.0580, -0.0427,  ...,  0.0080, -0.0037,  0.0870],\n",
      "        ...,\n",
      "        [ 0.1405,  0.0716,  0.0564,  ...,  0.0284,  0.0410,  0.0939],\n",
      "        [ 0.0787, -0.0565, -0.0220,  ...,  0.0265,  0.0567,  0.0538],\n",
      "        [ 0.0821, -0.0031,  0.0140,  ...,  0.0121, -0.0127,  0.0147]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "torch.Size([2304, 768])\n"
     ]
    }
   ],
   "source": [
    "print(my_product)\n",
    "print(my_product.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## minimal example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import LinearOperator, eigsh\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "DEFAULT_PHYS_BS = 1000\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "\n",
    "def iterate_dataset(dataset: Dataset, batch_size: int):\n",
    "    \"\"\"Iterate through a dataset, yielding batches of data.\"\"\"\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    #print(device)\n",
    "    for (batch_X, batch_y) in loader:\n",
    "        yield batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "def compute_hvp(network: nn.Module, loss_fn: nn.Module,\n",
    "                dataset: Dataset, vector: Tensor, physical_batch_size: int = DEFAULT_PHYS_BS):\n",
    "    \"\"\"Compute a Hessian-vector product.\"\"\"\n",
    "    p = len(parameters_to_vector(network.parameters()))\n",
    "    n = len(dataset)\n",
    "    hvp = torch.zeros(p, dtype=torch.float, device=device)\n",
    "    vector = vector.to(device)\n",
    "    for (X, y) in iterate_dataset(dataset, physical_batch_size):\n",
    "        #loss = loss_fn(network(X), y) / n\n",
    "        loss = loss_fn(network(X.to(device)), torch.nn.functional.one_hot(y.to(device), num_classes=10).float()) / n\n",
    "        #print(loss)\n",
    "        #for param in network.parameters():\n",
    "        #    print(param.data)\n",
    "        \"\"\"\n",
    "        param_list = []\n",
    "        for param in network.parameters():\n",
    "            param_list.append(param)\n",
    "            assert param.requires_grad\n",
    "        beta = torch.square(param_list[0]) - torch.square(param_list[1])\n",
    "        loss = 0.25*torch.mean((X@beta-y)**2)\n",
    "        \"\"\"\n",
    "        #loss = loss_fn(network(X), y) / n\n",
    "        #loss = 0.25 * torch.mean((network(X).squeeze()-y.squeeze())**2)\n",
    "        grads = torch.autograd.grad(loss, inputs=network.parameters(), create_graph=True)\n",
    "        dot = parameters_to_vector(grads).mul(vector).sum()\n",
    "        grads = [g.contiguous() for g in torch.autograd.grad(dot, network.parameters(), retain_graph=True)]\n",
    "        hvp += parameters_to_vector(grads)\n",
    "    return hvp\n",
    "\n",
    "\n",
    "def lanczos(matrix_vector, dim: int, neigs: int, which=\"SA\"):\n",
    "    \"\"\" Invoke the Lanczos algorithm to compute the leading eigenvalues and eigenvectors of a matrix / linear operator\n",
    "    (which we can access via matrix-vector products). \"\"\"\n",
    "\n",
    "    def mv(vec: np.ndarray):\n",
    "        gpu_vec = torch.tensor(vec, dtype=torch.float).to(device)\n",
    "        return matrix_vector(gpu_vec)\n",
    "\n",
    "    operator = LinearOperator((dim, dim), matvec=mv)\n",
    "    l_evals, l_evecs = eigsh(operator, neigs, which=which)\n",
    "    #s_evals, s_evecs= eigsh(operator, neigs, which='SM')\n",
    "    return torch.from_numpy(np.ascontiguousarray(l_evals[::-1]).copy()).float(), \\\n",
    "           torch.from_numpy(np.ascontiguousarray(np.flip(l_evecs, -1)).copy()).float()\n",
    "\n",
    "def get_hessian_eigenvalues(network: nn.Module, loss_fn: nn.Module, dataset: Dataset,\n",
    "                            neigs=6, physical_batch_size=1000):\n",
    "    #vector_test = torch.ones(200)\n",
    "    #print(compute_hvp(network, loss_fn, dataset, vector_test, physical_batch_size=physical_batch_size))\n",
    "    #sys.exit()\n",
    "    \"\"\" Compute the leading Hessian eigenvalues. \"\"\"\n",
    "    hvp_delta = lambda delta: compute_hvp(network, loss_fn, dataset,\n",
    "                                          delta, physical_batch_size=physical_batch_size).detach().cpu()\n",
    "    nparams = len(parameters_to_vector((network.parameters())))\n",
    "    l_evals, l_evecs = lanczos(hvp_delta, nparams, neigs=neigs)\n",
    "    return l_evals, l_evecs\n",
    "\n",
    "def get_grad_norm(model):\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        param_norm = p.grad.data.norm(2)\n",
    "        total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** (1. / 2)\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------\n",
    "# LoRA wrapper for Linear\n",
    "# ----------------------\n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, r=4, alpha=1.0):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
    "        \n",
    "        # Low-rank adapters\n",
    "        self.r = r\n",
    "        if r > 0:\n",
    "            self.A = nn.Linear(in_features, r, bias=False)\n",
    "            self.B = nn.Linear(r, out_features, bias=False)\n",
    "            # Scale factor\n",
    "            self.scaling = alpha / r\n",
    "        else:\n",
    "            self.A, self.B, self.scaling = None, None, None\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = self.linear(x)\n",
    "        if self.r > 0:\n",
    "            lora_update = self.B(self.A(x)) * self.scaling\n",
    "            result = result + lora_update\n",
    "        return result\n",
    "\n",
    "# ----------------------\n",
    "# Two-layer MLP with LoRA\n",
    "# ----------------------\n",
    "class LoRAMLP(nn.Module):\n",
    "    def __init__(self, input_dim=28*28, hidden_dim=256, num_classes=10, r=4):\n",
    "        super().__init__()\n",
    "        #self.fc1 = LoRALinear(input_dim, hidden_dim, r=r)\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = LoRALinear(hidden_dim, num_classes, r=r)\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, layer_norm=False):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if layer_norm:\n",
    "            x = F.layer_norm(x, (self.hidden_dim, ))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# ----------------------\n",
    "# Training Loop\n",
    "# ----------------------\n",
    "loss_fn = torch.nn.MSELoss() #torch.nn.CrossEntropyLoss()\n",
    "def train(model, device, train_loader, optimizer, epoch, layer_norm, analysis_dataset):\n",
    "    model.train()\n",
    "    losses, eigs, grad_norms = [], [], []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, layer_norm)\n",
    "        target = F.one_hot(target, num_classes=10).float()\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            losses.append(loss.item())\n",
    "            l_evals, _ = get_hessian_eigenvalues(model, loss_fn, analysis_dataset, neigs=6, physical_batch_size=1000)\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}]\\tLoss: {loss.item():.6f}\\tEigs: {l_evals[0].item():.6f}\")\n",
    "            eigs.append(l_evals[0])\n",
    "            grad_norm = get_grad_norm(model)\n",
    "            grad_norms.append(grad_norm)\n",
    "\n",
    "    return losses, eigs, grad_norms\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            onehot_target = F.one_hot(target, num_classes=10).float()\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, onehot_target).item()\n",
    "            pred = torch.abs(output-1).argmin(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/u/lucmon/lucmon/mlopt/notebook/lora_test.ipynb Cell 34\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcc-login4/u/lucmon/lucmon/mlopt/notebook/lora_test.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcc-login4/u/lucmon/lucmon/mlopt/notebook/lora_test.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcc-login4/u/lucmon/lucmon/mlopt/notebook/lora_test.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([transforms\u001b[39m.\u001b[39mToTensor()])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcc-login4/u/lucmon/lucmon/mlopt/notebook/lora_test.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mMNIST(\u001b[39m'\u001b[39m\u001b[39m./data\u001b[39m\u001b[39m'\u001b[39m, train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, transform\u001b[39m=\u001b[39mtransform)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcc-login4/u/lucmon/lucmon/mlopt/notebook/lora_test.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mMNIST(\u001b[39m'\u001b[39m\u001b[39m./data\u001b[39m\u001b[39m'\u001b[39m, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, transform\u001b[39m=\u001b[39mtransform)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "analysis_dataset = torch.utils.data.Subset(train_dataset, torch.arange(100))\n",
    "train_loader = DataLoader(analysis_dataset, batch_size=100, shuffle=True)\n",
    "\"\"\"\n",
    "# Model + Optimizer\n",
    "model = LoRAMLP(r=8).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train\n",
    "loss_norm = []\n",
    "for epoch in range(1, 6):\n",
    "    losses = train(model, device, train_loader, optimizer, epoch, layer_norm=True)\n",
    "    test(model, device, test_loader)\n",
    "    loss_norm.extend(losses)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight torch.Size([256, 784]) True\n",
      "fc1.bias torch.Size([256]) True\n",
      "fc2.linear.weight torch.Size([10, 256]) True\n",
      "fc2.A.weight torch.Size([8, 256]) True\n",
      "fc2.B.weight torch.Size([10, 8]) True\n"
     ]
    }
   ],
   "source": [
    "model = LoRAMLP(r=8).to(device)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/100]\tLoss: 0.346738\tEigs: -0.005118\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1087/10000 (10.87%)\n",
      "\n",
      "Train Epoch: 2 [0/100]\tLoss: 0.614055\tEigs: -0.003866\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 2285/10000 (22.85%)\n",
      "\n",
      "Train Epoch: 3 [0/100]\tLoss: 0.157624\tEigs: -0.003313\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 3468/10000 (34.68%)\n",
      "\n",
      "Train Epoch: 4 [0/100]\tLoss: 0.082964\tEigs: -0.003717\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 3700/10000 (37.00%)\n",
      "\n",
      "Train Epoch: 5 [0/100]\tLoss: 0.148492\tEigs: -0.003902\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 3722/10000 (37.22%)\n",
      "\n",
      "Train Epoch: 6 [0/100]\tLoss: 0.142685\tEigs: -0.003773\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 3944/10000 (39.44%)\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "loss_norm_run = []\n",
    "eigs_norm_run = []\n",
    "grads_norm_run = []\n",
    "for runs in range(1):\n",
    "    model = LoRAMLP(r=8).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train\n",
    "    loss_norm = []\n",
    "    eigs_norm = []\n",
    "    grads_norm = []\n",
    "    for epoch in range(1, 50):\n",
    "        losses, eigs, grads = train(model, device, train_loader, optimizer, epoch, layer_norm=True, analysis_dataset=analysis_dataset)\n",
    "        test(model, device, test_loader)\n",
    "        loss_norm.extend(losses)\n",
    "        eigs_norm.extend(eigs)\n",
    "        grads_norm.extend(grads)\n",
    "    loss_norm_run.append(loss_norm)\n",
    "    eigs_norm_run.append(eigs_norm)\n",
    "    grads_norm_run.append(grads_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6a64667910>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_norm_run[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6a74106490>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(eigs_norm_run[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6a7c46ccd0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "plt.plot(grads_norm_run[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000]\tLoss: 2.311347\n",
      "Train Epoch: 1 [6400/60000]\tLoss: 0.274945\n",
      "Train Epoch: 1 [12800/60000]\tLoss: 0.301690\n",
      "Train Epoch: 1 [19200/60000]\tLoss: 0.426659\n",
      "Train Epoch: 1 [25600/60000]\tLoss: 0.321909\n",
      "Train Epoch: 1 [32000/60000]\tLoss: 0.101809\n",
      "Train Epoch: 1 [38400/60000]\tLoss: 0.466030\n",
      "Train Epoch: 1 [44800/60000]\tLoss: 0.152469\n",
      "Train Epoch: 1 [51200/60000]\tLoss: 0.223822\n",
      "Train Epoch: 1 [57600/60000]\tLoss: 0.221972\n",
      "\n",
      "Test set: Average loss: 0.1432, Accuracy: 9585/10000 (95.85%)\n",
      "\n",
      "Train Epoch: 2 [0/60000]\tLoss: 0.101318\n",
      "Train Epoch: 2 [6400/60000]\tLoss: 0.188628\n",
      "Train Epoch: 2 [12800/60000]\tLoss: 0.291055\n",
      "Train Epoch: 2 [19200/60000]\tLoss: 0.082511\n",
      "Train Epoch: 2 [25600/60000]\tLoss: 0.125436\n",
      "Train Epoch: 2 [32000/60000]\tLoss: 0.128195\n",
      "Train Epoch: 2 [38400/60000]\tLoss: 0.045317\n",
      "Train Epoch: 2 [44800/60000]\tLoss: 0.101418\n",
      "Train Epoch: 2 [51200/60000]\tLoss: 0.103786\n",
      "Train Epoch: 2 [57600/60000]\tLoss: 0.067739\n",
      "\n",
      "Test set: Average loss: 0.1026, Accuracy: 9692/10000 (96.92%)\n",
      "\n",
      "Train Epoch: 3 [0/60000]\tLoss: 0.060433\n",
      "Train Epoch: 3 [6400/60000]\tLoss: 0.087148\n",
      "Train Epoch: 3 [12800/60000]\tLoss: 0.028754\n",
      "Train Epoch: 3 [19200/60000]\tLoss: 0.083139\n",
      "Train Epoch: 3 [25600/60000]\tLoss: 0.061444\n",
      "Train Epoch: 3 [32000/60000]\tLoss: 0.102260\n",
      "Train Epoch: 3 [38400/60000]\tLoss: 0.015383\n",
      "Train Epoch: 3 [44800/60000]\tLoss: 0.036427\n",
      "Train Epoch: 3 [51200/60000]\tLoss: 0.070448\n",
      "Train Epoch: 3 [57600/60000]\tLoss: 0.050912\n",
      "\n",
      "Test set: Average loss: 0.0836, Accuracy: 9734/10000 (97.34%)\n",
      "\n",
      "Train Epoch: 4 [0/60000]\tLoss: 0.018873\n",
      "Train Epoch: 4 [6400/60000]\tLoss: 0.028653\n",
      "Train Epoch: 4 [12800/60000]\tLoss: 0.050509\n",
      "Train Epoch: 4 [19200/60000]\tLoss: 0.036458\n",
      "Train Epoch: 4 [25600/60000]\tLoss: 0.022861\n",
      "Train Epoch: 4 [32000/60000]\tLoss: 0.077356\n",
      "Train Epoch: 4 [38400/60000]\tLoss: 0.007627\n",
      "Train Epoch: 4 [44800/60000]\tLoss: 0.013150\n",
      "Train Epoch: 4 [51200/60000]\tLoss: 0.027003\n",
      "Train Epoch: 4 [57600/60000]\tLoss: 0.091802\n",
      "\n",
      "Test set: Average loss: 0.0740, Accuracy: 9780/10000 (97.80%)\n",
      "\n",
      "Train Epoch: 5 [0/60000]\tLoss: 0.007957\n",
      "Train Epoch: 5 [6400/60000]\tLoss: 0.009541\n",
      "Train Epoch: 5 [12800/60000]\tLoss: 0.038661\n",
      "Train Epoch: 5 [19200/60000]\tLoss: 0.011650\n",
      "Train Epoch: 5 [25600/60000]\tLoss: 0.011556\n",
      "Train Epoch: 5 [32000/60000]\tLoss: 0.032701\n",
      "Train Epoch: 5 [38400/60000]\tLoss: 0.029273\n",
      "Train Epoch: 5 [44800/60000]\tLoss: 0.170685\n",
      "Train Epoch: 5 [51200/60000]\tLoss: 0.054143\n",
      "Train Epoch: 5 [57600/60000]\tLoss: 0.022650\n",
      "\n",
      "Test set: Average loss: 0.0723, Accuracy: 9769/10000 (97.69%)\n",
      "\n",
      "Train Epoch: 1 [0/60000]\tLoss: 2.310303\n",
      "Train Epoch: 1 [6400/60000]\tLoss: 0.597645\n",
      "Train Epoch: 1 [12800/60000]\tLoss: 0.090789\n",
      "Train Epoch: 1 [19200/60000]\tLoss: 0.215698\n",
      "Train Epoch: 1 [25600/60000]\tLoss: 0.213497\n",
      "Train Epoch: 1 [32000/60000]\tLoss: 0.098487\n",
      "Train Epoch: 1 [38400/60000]\tLoss: 0.063394\n",
      "Train Epoch: 1 [44800/60000]\tLoss: 0.184739\n",
      "Train Epoch: 1 [51200/60000]\tLoss: 0.232918\n",
      "Train Epoch: 1 [57600/60000]\tLoss: 0.112111\n",
      "\n",
      "Test set: Average loss: 0.1444, Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Train Epoch: 2 [0/60000]\tLoss: 0.084823\n",
      "Train Epoch: 2 [6400/60000]\tLoss: 0.096595\n",
      "Train Epoch: 2 [12800/60000]\tLoss: 0.236082\n",
      "Train Epoch: 2 [19200/60000]\tLoss: 0.278166\n",
      "Train Epoch: 2 [25600/60000]\tLoss: 0.023819\n",
      "Train Epoch: 2 [32000/60000]\tLoss: 0.068990\n",
      "Train Epoch: 2 [38400/60000]\tLoss: 0.050866\n",
      "Train Epoch: 2 [44800/60000]\tLoss: 0.147078\n",
      "Train Epoch: 2 [51200/60000]\tLoss: 0.086603\n",
      "Train Epoch: 2 [57600/60000]\tLoss: 0.110324\n",
      "\n",
      "Test set: Average loss: 0.1061, Accuracy: 9684/10000 (96.84%)\n",
      "\n",
      "Train Epoch: 3 [0/60000]\tLoss: 0.060623\n",
      "Train Epoch: 3 [6400/60000]\tLoss: 0.069443\n",
      "Train Epoch: 3 [12800/60000]\tLoss: 0.070220\n",
      "Train Epoch: 3 [19200/60000]\tLoss: 0.158687\n",
      "Train Epoch: 3 [25600/60000]\tLoss: 0.034200\n",
      "Train Epoch: 3 [32000/60000]\tLoss: 0.035688\n",
      "Train Epoch: 3 [38400/60000]\tLoss: 0.069300\n",
      "Train Epoch: 3 [44800/60000]\tLoss: 0.063937\n",
      "Train Epoch: 3 [51200/60000]\tLoss: 0.163472\n",
      "Train Epoch: 3 [57600/60000]\tLoss: 0.063643\n",
      "\n",
      "Test set: Average loss: 0.0813, Accuracy: 9763/10000 (97.63%)\n",
      "\n",
      "Train Epoch: 4 [0/60000]\tLoss: 0.015771\n",
      "Train Epoch: 4 [6400/60000]\tLoss: 0.034309\n",
      "Train Epoch: 4 [12800/60000]\tLoss: 0.047856\n",
      "Train Epoch: 4 [19200/60000]\tLoss: 0.032093\n",
      "Train Epoch: 4 [25600/60000]\tLoss: 0.051533\n",
      "Train Epoch: 4 [32000/60000]\tLoss: 0.065038\n",
      "Train Epoch: 4 [38400/60000]\tLoss: 0.083361\n",
      "Train Epoch: 4 [44800/60000]\tLoss: 0.060240\n",
      "Train Epoch: 4 [51200/60000]\tLoss: 0.110900\n",
      "Train Epoch: 4 [57600/60000]\tLoss: 0.012642\n",
      "\n",
      "Test set: Average loss: 0.0749, Accuracy: 9763/10000 (97.63%)\n",
      "\n",
      "Train Epoch: 5 [0/60000]\tLoss: 0.026928\n",
      "Train Epoch: 5 [6400/60000]\tLoss: 0.040678\n",
      "Train Epoch: 5 [12800/60000]\tLoss: 0.061553\n",
      "Train Epoch: 5 [19200/60000]\tLoss: 0.013363\n",
      "Train Epoch: 5 [25600/60000]\tLoss: 0.043704\n",
      "Train Epoch: 5 [32000/60000]\tLoss: 0.060901\n",
      "Train Epoch: 5 [38400/60000]\tLoss: 0.021280\n",
      "Train Epoch: 5 [44800/60000]\tLoss: 0.116919\n",
      "Train Epoch: 5 [51200/60000]\tLoss: 0.032758\n",
      "Train Epoch: 5 [57600/60000]\tLoss: 0.036201\n",
      "\n",
      "Test set: Average loss: 0.0678, Accuracy: 9788/10000 (97.88%)\n",
      "\n",
      "Train Epoch: 1 [0/60000]\tLoss: 2.311380\n",
      "Train Epoch: 1 [6400/60000]\tLoss: 0.420014\n",
      "Train Epoch: 1 [12800/60000]\tLoss: 0.364319\n",
      "Train Epoch: 1 [19200/60000]\tLoss: 0.263280\n",
      "Train Epoch: 1 [25600/60000]\tLoss: 0.520395\n",
      "Train Epoch: 1 [32000/60000]\tLoss: 0.163107\n",
      "Train Epoch: 1 [38400/60000]\tLoss: 0.211895\n",
      "Train Epoch: 1 [44800/60000]\tLoss: 0.218937\n",
      "Train Epoch: 1 [51200/60000]\tLoss: 0.236206\n",
      "Train Epoch: 1 [57600/60000]\tLoss: 0.132541\n",
      "\n",
      "Test set: Average loss: 0.1512, Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Train Epoch: 2 [0/60000]\tLoss: 0.060579\n",
      "Train Epoch: 2 [6400/60000]\tLoss: 0.065305\n",
      "Train Epoch: 2 [12800/60000]\tLoss: 0.083057\n",
      "Train Epoch: 2 [19200/60000]\tLoss: 0.221999\n",
      "Train Epoch: 2 [25600/60000]\tLoss: 0.156482\n",
      "Train Epoch: 2 [32000/60000]\tLoss: 0.121581\n",
      "Train Epoch: 2 [38400/60000]\tLoss: 0.169226\n",
      "Train Epoch: 2 [44800/60000]\tLoss: 0.036496\n",
      "Train Epoch: 2 [51200/60000]\tLoss: 0.210250\n",
      "Train Epoch: 2 [57600/60000]\tLoss: 0.130163\n",
      "\n",
      "Test set: Average loss: 0.1069, Accuracy: 9672/10000 (96.72%)\n",
      "\n",
      "Train Epoch: 3 [0/60000]\tLoss: 0.150706\n",
      "Train Epoch: 3 [6400/60000]\tLoss: 0.093123\n",
      "Train Epoch: 3 [12800/60000]\tLoss: 0.073062\n",
      "Train Epoch: 3 [19200/60000]\tLoss: 0.108711\n",
      "Train Epoch: 3 [25600/60000]\tLoss: 0.108720\n",
      "Train Epoch: 3 [32000/60000]\tLoss: 0.206054\n",
      "Train Epoch: 3 [38400/60000]\tLoss: 0.029606\n",
      "Train Epoch: 3 [44800/60000]\tLoss: 0.118493\n",
      "Train Epoch: 3 [51200/60000]\tLoss: 0.177181\n",
      "Train Epoch: 3 [57600/60000]\tLoss: 0.104521\n",
      "\n",
      "Test set: Average loss: 0.0850, Accuracy: 9743/10000 (97.43%)\n",
      "\n",
      "Train Epoch: 4 [0/60000]\tLoss: 0.091636\n",
      "Train Epoch: 4 [6400/60000]\tLoss: 0.044267\n",
      "Train Epoch: 4 [12800/60000]\tLoss: 0.061120\n",
      "Train Epoch: 4 [19200/60000]\tLoss: 0.039319\n",
      "Train Epoch: 4 [25600/60000]\tLoss: 0.076388\n",
      "Train Epoch: 4 [32000/60000]\tLoss: 0.134695\n",
      "Train Epoch: 4 [38400/60000]\tLoss: 0.071580\n",
      "Train Epoch: 4 [44800/60000]\tLoss: 0.156416\n",
      "Train Epoch: 4 [51200/60000]\tLoss: 0.168533\n",
      "Train Epoch: 4 [57600/60000]\tLoss: 0.036235\n",
      "\n",
      "Test set: Average loss: 0.0814, Accuracy: 9747/10000 (97.47%)\n",
      "\n",
      "Train Epoch: 5 [0/60000]\tLoss: 0.046935\n",
      "Train Epoch: 5 [6400/60000]\tLoss: 0.038058\n",
      "Train Epoch: 5 [12800/60000]\tLoss: 0.069052\n",
      "Train Epoch: 5 [19200/60000]\tLoss: 0.010525\n",
      "Train Epoch: 5 [25600/60000]\tLoss: 0.007934\n",
      "Train Epoch: 5 [32000/60000]\tLoss: 0.050050\n",
      "Train Epoch: 5 [38400/60000]\tLoss: 0.071764\n",
      "Train Epoch: 5 [44800/60000]\tLoss: 0.041757\n",
      "Train Epoch: 5 [51200/60000]\tLoss: 0.130820\n",
      "Train Epoch: 5 [57600/60000]\tLoss: 0.012390\n",
      "\n",
      "Test set: Average loss: 0.0716, Accuracy: 9782/10000 (97.82%)\n",
      "\n",
      "Train Epoch: 1 [0/60000]\tLoss: 2.290030\n",
      "Train Epoch: 1 [6400/60000]\tLoss: 0.427907\n",
      "Train Epoch: 1 [12800/60000]\tLoss: 0.307472\n",
      "Train Epoch: 1 [19200/60000]\tLoss: 0.398709\n",
      "Train Epoch: 1 [25600/60000]\tLoss: 0.108233\n",
      "Train Epoch: 1 [32000/60000]\tLoss: 0.250078\n",
      "Train Epoch: 1 [38400/60000]\tLoss: 0.372412\n",
      "Train Epoch: 1 [44800/60000]\tLoss: 0.470766\n",
      "Train Epoch: 1 [51200/60000]\tLoss: 0.147743\n",
      "Train Epoch: 1 [57600/60000]\tLoss: 0.108321\n",
      "\n",
      "Test set: Average loss: 0.1584, Accuracy: 9527/10000 (95.27%)\n",
      "\n",
      "Train Epoch: 2 [0/60000]\tLoss: 0.170746\n",
      "Train Epoch: 2 [6400/60000]\tLoss: 0.155658\n",
      "Train Epoch: 2 [12800/60000]\tLoss: 0.173139\n",
      "Train Epoch: 2 [19200/60000]\tLoss: 0.113754\n",
      "Train Epoch: 2 [25600/60000]\tLoss: 0.111388\n",
      "Train Epoch: 2 [32000/60000]\tLoss: 0.051160\n",
      "Train Epoch: 2 [38400/60000]\tLoss: 0.100259\n",
      "Train Epoch: 2 [44800/60000]\tLoss: 0.061448\n",
      "Train Epoch: 2 [51200/60000]\tLoss: 0.012385\n",
      "Train Epoch: 2 [57600/60000]\tLoss: 0.075058\n",
      "\n",
      "Test set: Average loss: 0.1022, Accuracy: 9686/10000 (96.86%)\n",
      "\n",
      "Train Epoch: 3 [0/60000]\tLoss: 0.048650\n",
      "Train Epoch: 3 [6400/60000]\tLoss: 0.081013\n",
      "Train Epoch: 3 [12800/60000]\tLoss: 0.097667\n",
      "Train Epoch: 3 [19200/60000]\tLoss: 0.089335\n",
      "Train Epoch: 3 [25600/60000]\tLoss: 0.101650\n",
      "Train Epoch: 3 [32000/60000]\tLoss: 0.015927\n",
      "Train Epoch: 3 [38400/60000]\tLoss: 0.108751\n",
      "Train Epoch: 3 [44800/60000]\tLoss: 0.108888\n",
      "Train Epoch: 3 [51200/60000]\tLoss: 0.061516\n",
      "Train Epoch: 3 [57600/60000]\tLoss: 0.040339\n",
      "\n",
      "Test set: Average loss: 0.0986, Accuracy: 9691/10000 (96.91%)\n",
      "\n",
      "Train Epoch: 4 [0/60000]\tLoss: 0.012933\n",
      "Train Epoch: 4 [6400/60000]\tLoss: 0.017196\n",
      "Train Epoch: 4 [12800/60000]\tLoss: 0.038002\n",
      "Train Epoch: 4 [19200/60000]\tLoss: 0.017714\n",
      "Train Epoch: 4 [25600/60000]\tLoss: 0.021064\n",
      "Train Epoch: 4 [32000/60000]\tLoss: 0.032048\n",
      "Train Epoch: 4 [38400/60000]\tLoss: 0.088506\n",
      "Train Epoch: 4 [44800/60000]\tLoss: 0.016361\n",
      "Train Epoch: 4 [51200/60000]\tLoss: 0.010386\n",
      "Train Epoch: 4 [57600/60000]\tLoss: 0.081584\n",
      "\n",
      "Test set: Average loss: 0.0776, Accuracy: 9767/10000 (97.67%)\n",
      "\n",
      "Train Epoch: 5 [0/60000]\tLoss: 0.204578\n",
      "Train Epoch: 5 [6400/60000]\tLoss: 0.005158\n",
      "Train Epoch: 5 [12800/60000]\tLoss: 0.059581\n",
      "Train Epoch: 5 [19200/60000]\tLoss: 0.108126\n",
      "Train Epoch: 5 [25600/60000]\tLoss: 0.007230\n",
      "Train Epoch: 5 [32000/60000]\tLoss: 0.038974\n",
      "Train Epoch: 5 [38400/60000]\tLoss: 0.018070\n",
      "Train Epoch: 5 [44800/60000]\tLoss: 0.026627\n",
      "Train Epoch: 5 [51200/60000]\tLoss: 0.075099\n",
      "Train Epoch: 5 [57600/60000]\tLoss: 0.042636\n",
      "\n",
      "Test set: Average loss: 0.0732, Accuracy: 9783/10000 (97.83%)\n",
      "\n",
      "Train Epoch: 1 [0/60000]\tLoss: 2.320861\n",
      "Train Epoch: 1 [6400/60000]\tLoss: 0.366527\n",
      "Train Epoch: 1 [12800/60000]\tLoss: 0.424121\n",
      "Train Epoch: 1 [19200/60000]\tLoss: 0.389549\n",
      "Train Epoch: 1 [25600/60000]\tLoss: 0.151481\n",
      "Train Epoch: 1 [32000/60000]\tLoss: 0.123987\n",
      "Train Epoch: 1 [38400/60000]\tLoss: 0.186265\n",
      "Train Epoch: 1 [44800/60000]\tLoss: 0.173723\n",
      "Train Epoch: 1 [51200/60000]\tLoss: 0.141922\n",
      "Train Epoch: 1 [57600/60000]\tLoss: 0.194017\n",
      "\n",
      "Test set: Average loss: 0.1525, Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Train Epoch: 2 [0/60000]\tLoss: 0.051871\n",
      "Train Epoch: 2 [6400/60000]\tLoss: 0.081568\n",
      "Train Epoch: 2 [12800/60000]\tLoss: 0.142584\n",
      "Train Epoch: 2 [19200/60000]\tLoss: 0.150283\n",
      "Train Epoch: 2 [25600/60000]\tLoss: 0.068772\n",
      "Train Epoch: 2 [32000/60000]\tLoss: 0.195254\n",
      "Train Epoch: 2 [38400/60000]\tLoss: 0.330663\n",
      "Train Epoch: 2 [44800/60000]\tLoss: 0.086229\n",
      "Train Epoch: 2 [51200/60000]\tLoss: 0.063299\n",
      "Train Epoch: 2 [57600/60000]\tLoss: 0.051557\n",
      "\n",
      "Test set: Average loss: 0.0963, Accuracy: 9708/10000 (97.08%)\n",
      "\n",
      "Train Epoch: 3 [0/60000]\tLoss: 0.075305\n",
      "Train Epoch: 3 [6400/60000]\tLoss: 0.059188\n",
      "Train Epoch: 3 [12800/60000]\tLoss: 0.067253\n",
      "Train Epoch: 3 [19200/60000]\tLoss: 0.144031\n",
      "Train Epoch: 3 [25600/60000]\tLoss: 0.038617\n",
      "Train Epoch: 3 [32000/60000]\tLoss: 0.049610\n",
      "Train Epoch: 3 [38400/60000]\tLoss: 0.032645\n",
      "Train Epoch: 3 [44800/60000]\tLoss: 0.047885\n",
      "Train Epoch: 3 [51200/60000]\tLoss: 0.084292\n",
      "Train Epoch: 3 [57600/60000]\tLoss: 0.062176\n",
      "\n",
      "Test set: Average loss: 0.0726, Accuracy: 9770/10000 (97.70%)\n",
      "\n",
      "Train Epoch: 4 [0/60000]\tLoss: 0.079058\n",
      "Train Epoch: 4 [6400/60000]\tLoss: 0.082584\n",
      "Train Epoch: 4 [12800/60000]\tLoss: 0.048152\n",
      "Train Epoch: 4 [19200/60000]\tLoss: 0.037260\n",
      "Train Epoch: 4 [25600/60000]\tLoss: 0.034722\n",
      "Train Epoch: 4 [32000/60000]\tLoss: 0.067738\n",
      "Train Epoch: 4 [38400/60000]\tLoss: 0.138273\n",
      "Train Epoch: 4 [44800/60000]\tLoss: 0.043935\n",
      "Train Epoch: 4 [51200/60000]\tLoss: 0.087603\n",
      "Train Epoch: 4 [57600/60000]\tLoss: 0.015624\n",
      "\n",
      "Test set: Average loss: 0.0738, Accuracy: 9766/10000 (97.66%)\n",
      "\n",
      "Train Epoch: 5 [0/60000]\tLoss: 0.113139\n",
      "Train Epoch: 5 [6400/60000]\tLoss: 0.023950\n",
      "Train Epoch: 5 [12800/60000]\tLoss: 0.011558\n",
      "Train Epoch: 5 [19200/60000]\tLoss: 0.017306\n",
      "Train Epoch: 5 [25600/60000]\tLoss: 0.107404\n",
      "Train Epoch: 5 [32000/60000]\tLoss: 0.102897\n",
      "Train Epoch: 5 [38400/60000]\tLoss: 0.071541\n",
      "Train Epoch: 5 [44800/60000]\tLoss: 0.035267\n",
      "Train Epoch: 5 [51200/60000]\tLoss: 0.017144\n",
      "Train Epoch: 5 [57600/60000]\tLoss: 0.013898\n",
      "\n",
      "Test set: Average loss: 0.0648, Accuracy: 9805/10000 (98.05%)\n",
      "\n",
      "Train Epoch: 1 [0/60000]\tLoss: 2.294574\n",
      "Train Epoch: 1 [6400/60000]\tLoss: 0.350829\n",
      "Train Epoch: 1 [12800/60000]\tLoss: 0.154032\n",
      "Train Epoch: 1 [19200/60000]\tLoss: 0.430900\n",
      "Train Epoch: 1 [25600/60000]\tLoss: 0.184474\n",
      "Train Epoch: 1 [32000/60000]\tLoss: 0.171102\n",
      "Train Epoch: 1 [38400/60000]\tLoss: 0.232271\n",
      "Train Epoch: 1 [44800/60000]\tLoss: 0.264387\n",
      "Train Epoch: 1 [51200/60000]\tLoss: 0.130819\n",
      "Train Epoch: 1 [57600/60000]\tLoss: 0.100786\n",
      "\n",
      "Test set: Average loss: 0.1472, Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Train Epoch: 2 [0/60000]\tLoss: 0.338062\n",
      "Train Epoch: 2 [6400/60000]\tLoss: 0.109246\n",
      "Train Epoch: 2 [12800/60000]\tLoss: 0.037070\n",
      "Train Epoch: 2 [19200/60000]\tLoss: 0.170163\n",
      "Train Epoch: 2 [25600/60000]\tLoss: 0.107864\n",
      "Train Epoch: 2 [32000/60000]\tLoss: 0.085021\n",
      "Train Epoch: 2 [38400/60000]\tLoss: 0.045659\n",
      "Train Epoch: 2 [44800/60000]\tLoss: 0.065113\n",
      "Train Epoch: 2 [51200/60000]\tLoss: 0.073614\n",
      "Train Epoch: 2 [57600/60000]\tLoss: 0.107109\n",
      "\n",
      "Test set: Average loss: 0.0971, Accuracy: 9717/10000 (97.17%)\n",
      "\n",
      "Train Epoch: 3 [0/60000]\tLoss: 0.094798\n",
      "Train Epoch: 3 [6400/60000]\tLoss: 0.051967\n",
      "Train Epoch: 3 [12800/60000]\tLoss: 0.079522\n",
      "Train Epoch: 3 [19200/60000]\tLoss: 0.106039\n",
      "Train Epoch: 3 [25600/60000]\tLoss: 0.053141\n",
      "Train Epoch: 3 [32000/60000]\tLoss: 0.088182\n",
      "Train Epoch: 3 [38400/60000]\tLoss: 0.149598\n",
      "Train Epoch: 3 [44800/60000]\tLoss: 0.081662\n",
      "Train Epoch: 3 [51200/60000]\tLoss: 0.027433\n",
      "Train Epoch: 3 [57600/60000]\tLoss: 0.011842\n",
      "\n",
      "Test set: Average loss: 0.0910, Accuracy: 9713/10000 (97.13%)\n",
      "\n",
      "Train Epoch: 4 [0/60000]\tLoss: 0.043938\n",
      "Train Epoch: 4 [6400/60000]\tLoss: 0.054554\n",
      "Train Epoch: 4 [12800/60000]\tLoss: 0.018287\n",
      "Train Epoch: 4 [19200/60000]\tLoss: 0.043724\n",
      "Train Epoch: 4 [25600/60000]\tLoss: 0.021906\n",
      "Train Epoch: 4 [32000/60000]\tLoss: 0.031360\n",
      "Train Epoch: 4 [38400/60000]\tLoss: 0.027610\n",
      "Train Epoch: 4 [44800/60000]\tLoss: 0.170630\n",
      "Train Epoch: 4 [51200/60000]\tLoss: 0.050877\n",
      "Train Epoch: 4 [57600/60000]\tLoss: 0.028117\n",
      "\n",
      "Test set: Average loss: 0.0805, Accuracy: 9748/10000 (97.48%)\n",
      "\n",
      "Train Epoch: 5 [0/60000]\tLoss: 0.116439\n",
      "Train Epoch: 5 [6400/60000]\tLoss: 0.112144\n",
      "Train Epoch: 5 [12800/60000]\tLoss: 0.032935\n",
      "Train Epoch: 5 [19200/60000]\tLoss: 0.006629\n",
      "Train Epoch: 5 [25600/60000]\tLoss: 0.063146\n",
      "Train Epoch: 5 [32000/60000]\tLoss: 0.062031\n",
      "Train Epoch: 5 [38400/60000]\tLoss: 0.021666\n",
      "Train Epoch: 5 [44800/60000]\tLoss: 0.027898\n",
      "Train Epoch: 5 [51200/60000]\tLoss: 0.061993\n",
      "Train Epoch: 5 [57600/60000]\tLoss: 0.098411\n",
      "\n",
      "Test set: Average loss: 0.0768, Accuracy: 9766/10000 (97.66%)\n",
      "\n",
      "Train Epoch: 1 [0/60000]\tLoss: 2.303367\n",
      "Train Epoch: 1 [6400/60000]\tLoss: 0.380696\n",
      "Train Epoch: 1 [12800/60000]\tLoss: 0.293589\n",
      "Train Epoch: 1 [19200/60000]\tLoss: 0.202895\n",
      "Train Epoch: 1 [25600/60000]\tLoss: 0.249614\n",
      "Train Epoch: 1 [32000/60000]\tLoss: 0.467570\n",
      "Train Epoch: 1 [38400/60000]\tLoss: 0.120373\n",
      "Train Epoch: 1 [44800/60000]\tLoss: 0.200490\n",
      "Train Epoch: 1 [51200/60000]\tLoss: 0.076886\n",
      "Train Epoch: 1 [57600/60000]\tLoss: 0.180533\n",
      "\n",
      "Test set: Average loss: 0.1470, Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Train Epoch: 2 [0/60000]\tLoss: 0.148647\n",
      "Train Epoch: 2 [6400/60000]\tLoss: 0.171666\n",
      "Train Epoch: 2 [12800/60000]\tLoss: 0.048747\n",
      "Train Epoch: 2 [19200/60000]\tLoss: 0.231987\n",
      "Train Epoch: 2 [25600/60000]\tLoss: 0.092488\n",
      "Train Epoch: 2 [32000/60000]\tLoss: 0.127388\n",
      "Train Epoch: 2 [38400/60000]\tLoss: 0.169239\n",
      "Train Epoch: 2 [44800/60000]\tLoss: 0.054353\n",
      "Train Epoch: 2 [51200/60000]\tLoss: 0.055809\n",
      "Train Epoch: 2 [57600/60000]\tLoss: 0.068598\n",
      "\n",
      "Test set: Average loss: 0.1029, Accuracy: 9684/10000 (96.84%)\n",
      "\n",
      "Train Epoch: 3 [0/60000]\tLoss: 0.181220\n",
      "Train Epoch: 3 [6400/60000]\tLoss: 0.078735\n",
      "Train Epoch: 3 [12800/60000]\tLoss: 0.015972\n",
      "Train Epoch: 3 [19200/60000]\tLoss: 0.171329\n",
      "Train Epoch: 3 [25600/60000]\tLoss: 0.030360\n",
      "Train Epoch: 3 [32000/60000]\tLoss: 0.124635\n",
      "Train Epoch: 3 [38400/60000]\tLoss: 0.043776\n",
      "Train Epoch: 3 [44800/60000]\tLoss: 0.037533\n",
      "Train Epoch: 3 [51200/60000]\tLoss: 0.038199\n",
      "Train Epoch: 3 [57600/60000]\tLoss: 0.067907\n",
      "\n",
      "Test set: Average loss: 0.0849, Accuracy: 9746/10000 (97.46%)\n",
      "\n",
      "Train Epoch: 4 [0/60000]\tLoss: 0.081669\n",
      "Train Epoch: 4 [6400/60000]\tLoss: 0.105969\n",
      "Train Epoch: 4 [12800/60000]\tLoss: 0.031641\n",
      "Train Epoch: 4 [19200/60000]\tLoss: 0.153770\n",
      "Train Epoch: 4 [25600/60000]\tLoss: 0.009784\n",
      "Train Epoch: 4 [32000/60000]\tLoss: 0.026219\n",
      "Train Epoch: 4 [38400/60000]\tLoss: 0.114643\n",
      "Train Epoch: 4 [44800/60000]\tLoss: 0.113558\n",
      "Train Epoch: 4 [51200/60000]\tLoss: 0.046296\n",
      "Train Epoch: 4 [57600/60000]\tLoss: 0.013782\n",
      "\n",
      "Test set: Average loss: 0.0761, Accuracy: 9755/10000 (97.55%)\n",
      "\n",
      "Train Epoch: 5 [0/60000]\tLoss: 0.028865\n",
      "Train Epoch: 5 [6400/60000]\tLoss: 0.036041\n",
      "Train Epoch: 5 [12800/60000]\tLoss: 0.027795\n",
      "Train Epoch: 5 [19200/60000]\tLoss: 0.044747\n",
      "Train Epoch: 5 [25600/60000]\tLoss: 0.061966\n",
      "Train Epoch: 5 [32000/60000]\tLoss: 0.010350\n",
      "Train Epoch: 5 [38400/60000]\tLoss: 0.011670\n",
      "Train Epoch: 5 [44800/60000]\tLoss: 0.013166\n",
      "Train Epoch: 5 [51200/60000]\tLoss: 0.032884\n",
      "Train Epoch: 5 [57600/60000]\tLoss: 0.007115\n",
      "\n",
      "Test set: Average loss: 0.0658, Accuracy: 9793/10000 (97.93%)\n",
      "\n",
      "Train Epoch: 1 [0/60000]\tLoss: 2.287127\n",
      "Train Epoch: 1 [6400/60000]\tLoss: 0.428411\n",
      "Train Epoch: 1 [12800/60000]\tLoss: 0.325199\n",
      "Train Epoch: 1 [19200/60000]\tLoss: 0.273193\n",
      "Train Epoch: 1 [25600/60000]\tLoss: 0.152425\n",
      "Train Epoch: 1 [32000/60000]\tLoss: 0.218344\n",
      "Train Epoch: 1 [38400/60000]\tLoss: 0.197669\n",
      "Train Epoch: 1 [44800/60000]\tLoss: 0.178321\n",
      "Train Epoch: 1 [51200/60000]\tLoss: 0.201129\n",
      "Train Epoch: 1 [57600/60000]\tLoss: 0.174149\n",
      "\n",
      "Test set: Average loss: 0.1439, Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Train Epoch: 2 [0/60000]\tLoss: 0.158214\n",
      "Train Epoch: 2 [6400/60000]\tLoss: 0.101269\n",
      "Train Epoch: 2 [12800/60000]\tLoss: 0.211360\n",
      "Train Epoch: 2 [19200/60000]\tLoss: 0.090076\n",
      "Train Epoch: 2 [25600/60000]\tLoss: 0.127953\n",
      "Train Epoch: 2 [32000/60000]\tLoss: 0.070740\n",
      "Train Epoch: 2 [38400/60000]\tLoss: 0.289952\n",
      "Train Epoch: 2 [44800/60000]\tLoss: 0.150098\n",
      "Train Epoch: 2 [51200/60000]\tLoss: 0.152167\n",
      "Train Epoch: 2 [57600/60000]\tLoss: 0.059297\n",
      "\n",
      "Test set: Average loss: 0.1072, Accuracy: 9667/10000 (96.67%)\n",
      "\n",
      "Train Epoch: 3 [0/60000]\tLoss: 0.022161\n",
      "Train Epoch: 3 [6400/60000]\tLoss: 0.012765\n",
      "Train Epoch: 3 [12800/60000]\tLoss: 0.095932\n",
      "Train Epoch: 3 [19200/60000]\tLoss: 0.025984\n",
      "Train Epoch: 3 [25600/60000]\tLoss: 0.050522\n",
      "Train Epoch: 3 [32000/60000]\tLoss: 0.032869\n",
      "Train Epoch: 3 [38400/60000]\tLoss: 0.032668\n",
      "Train Epoch: 3 [44800/60000]\tLoss: 0.155451\n",
      "Train Epoch: 3 [51200/60000]\tLoss: 0.022919\n",
      "Train Epoch: 3 [57600/60000]\tLoss: 0.025968\n",
      "\n",
      "Test set: Average loss: 0.1051, Accuracy: 9686/10000 (96.86%)\n",
      "\n",
      "Train Epoch: 4 [0/60000]\tLoss: 0.012717\n",
      "Train Epoch: 4 [6400/60000]\tLoss: 0.053887\n",
      "Train Epoch: 4 [12800/60000]\tLoss: 0.033899\n",
      "Train Epoch: 4 [19200/60000]\tLoss: 0.117426\n",
      "Train Epoch: 4 [25600/60000]\tLoss: 0.084406\n",
      "Train Epoch: 4 [32000/60000]\tLoss: 0.052256\n",
      "Train Epoch: 4 [38400/60000]\tLoss: 0.037624\n",
      "Train Epoch: 4 [44800/60000]\tLoss: 0.031932\n",
      "Train Epoch: 4 [51200/60000]\tLoss: 0.033958\n",
      "Train Epoch: 4 [57600/60000]\tLoss: 0.053977\n",
      "\n",
      "Test set: Average loss: 0.0740, Accuracy: 9766/10000 (97.66%)\n",
      "\n",
      "Train Epoch: 5 [0/60000]\tLoss: 0.007869\n",
      "Train Epoch: 5 [6400/60000]\tLoss: 0.041808\n",
      "Train Epoch: 5 [12800/60000]\tLoss: 0.032589\n",
      "Train Epoch: 5 [19200/60000]\tLoss: 0.090397\n",
      "Train Epoch: 5 [25600/60000]\tLoss: 0.063228\n",
      "Train Epoch: 5 [32000/60000]\tLoss: 0.017539\n",
      "Train Epoch: 5 [38400/60000]\tLoss: 0.053014\n",
      "Train Epoch: 5 [44800/60000]\tLoss: 0.040140\n",
      "Train Epoch: 5 [51200/60000]\tLoss: 0.035474\n",
      "Train Epoch: 5 [57600/60000]\tLoss: 0.032985\n",
      "\n",
      "Test set: Average loss: 0.0769, Accuracy: 9751/10000 (97.51%)\n",
      "\n",
      "Train Epoch: 1 [0/60000]\tLoss: 2.318616\n",
      "Train Epoch: 1 [6400/60000]\tLoss: 0.382255\n",
      "Train Epoch: 1 [12800/60000]\tLoss: 0.311368\n",
      "Train Epoch: 1 [19200/60000]\tLoss: 0.149387\n",
      "Train Epoch: 1 [25600/60000]\tLoss: 0.200373\n",
      "Train Epoch: 1 [32000/60000]\tLoss: 0.110278\n",
      "Train Epoch: 1 [38400/60000]\tLoss: 0.132347\n",
      "Train Epoch: 1 [44800/60000]\tLoss: 0.135723\n",
      "Train Epoch: 1 [51200/60000]\tLoss: 0.270855\n",
      "Train Epoch: 1 [57600/60000]\tLoss: 0.161489\n",
      "\n",
      "Test set: Average loss: 0.1477, Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Train Epoch: 2 [0/60000]\tLoss: 0.170069\n",
      "Train Epoch: 2 [6400/60000]\tLoss: 0.119930\n",
      "Train Epoch: 2 [12800/60000]\tLoss: 0.125967\n",
      "Train Epoch: 2 [19200/60000]\tLoss: 0.161329\n",
      "Train Epoch: 2 [25600/60000]\tLoss: 0.174976\n",
      "Train Epoch: 2 [32000/60000]\tLoss: 0.196324\n",
      "Train Epoch: 2 [38400/60000]\tLoss: 0.084154\n",
      "Train Epoch: 2 [44800/60000]\tLoss: 0.082094\n",
      "Train Epoch: 2 [51200/60000]\tLoss: 0.031523\n",
      "Train Epoch: 2 [57600/60000]\tLoss: 0.132659\n",
      "\n",
      "Test set: Average loss: 0.0992, Accuracy: 9701/10000 (97.01%)\n",
      "\n",
      "Train Epoch: 3 [0/60000]\tLoss: 0.185372\n",
      "Train Epoch: 3 [6400/60000]\tLoss: 0.057262\n",
      "Train Epoch: 3 [12800/60000]\tLoss: 0.201189\n",
      "Train Epoch: 3 [19200/60000]\tLoss: 0.132538\n",
      "Train Epoch: 3 [25600/60000]\tLoss: 0.066867\n",
      "Train Epoch: 3 [32000/60000]\tLoss: 0.143395\n",
      "Train Epoch: 3 [38400/60000]\tLoss: 0.034522\n",
      "Train Epoch: 3 [44800/60000]\tLoss: 0.041024\n",
      "Train Epoch: 3 [51200/60000]\tLoss: 0.117885\n",
      "Train Epoch: 3 [57600/60000]\tLoss: 0.076474\n",
      "\n",
      "Test set: Average loss: 0.0886, Accuracy: 9735/10000 (97.35%)\n",
      "\n",
      "Train Epoch: 4 [0/60000]\tLoss: 0.041068\n",
      "Train Epoch: 4 [6400/60000]\tLoss: 0.021094\n",
      "Train Epoch: 4 [12800/60000]\tLoss: 0.067699\n",
      "Train Epoch: 4 [19200/60000]\tLoss: 0.075697\n",
      "Train Epoch: 4 [25600/60000]\tLoss: 0.096987\n",
      "Train Epoch: 4 [32000/60000]\tLoss: 0.013286\n",
      "Train Epoch: 4 [38400/60000]\tLoss: 0.099680\n",
      "Train Epoch: 4 [44800/60000]\tLoss: 0.097086\n",
      "Train Epoch: 4 [51200/60000]\tLoss: 0.049896\n",
      "Train Epoch: 4 [57600/60000]\tLoss: 0.092113\n",
      "\n",
      "Test set: Average loss: 0.0695, Accuracy: 9782/10000 (97.82%)\n",
      "\n",
      "Train Epoch: 5 [0/60000]\tLoss: 0.084643\n",
      "Train Epoch: 5 [6400/60000]\tLoss: 0.052224\n",
      "Train Epoch: 5 [12800/60000]\tLoss: 0.069868\n",
      "Train Epoch: 5 [19200/60000]\tLoss: 0.008156\n",
      "Train Epoch: 5 [25600/60000]\tLoss: 0.016306\n",
      "Train Epoch: 5 [32000/60000]\tLoss: 0.037256\n",
      "Train Epoch: 5 [38400/60000]\tLoss: 0.039867\n",
      "Train Epoch: 5 [44800/60000]\tLoss: 0.003269\n",
      "Train Epoch: 5 [51200/60000]\tLoss: 0.021380\n",
      "Train Epoch: 5 [57600/60000]\tLoss: 0.034296\n",
      "\n",
      "Test set: Average loss: 0.0665, Accuracy: 9795/10000 (97.95%)\n",
      "\n",
      "Train Epoch: 1 [0/60000]\tLoss: 2.296217\n",
      "Train Epoch: 1 [6400/60000]\tLoss: 0.189815\n",
      "Train Epoch: 1 [12800/60000]\tLoss: 0.400626\n",
      "Train Epoch: 1 [19200/60000]\tLoss: 0.430294\n",
      "Train Epoch: 1 [25600/60000]\tLoss: 0.134977\n",
      "Train Epoch: 1 [32000/60000]\tLoss: 0.176928\n",
      "Train Epoch: 1 [38400/60000]\tLoss: 0.209554\n",
      "Train Epoch: 1 [44800/60000]\tLoss: 0.167674\n",
      "Train Epoch: 1 [51200/60000]\tLoss: 0.298288\n",
      "Train Epoch: 1 [57600/60000]\tLoss: 0.178026\n",
      "\n",
      "Test set: Average loss: 0.1540, Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Train Epoch: 2 [0/60000]\tLoss: 0.155908\n",
      "Train Epoch: 2 [6400/60000]\tLoss: 0.135410\n",
      "Train Epoch: 2 [12800/60000]\tLoss: 0.202422\n",
      "Train Epoch: 2 [19200/60000]\tLoss: 0.180807\n",
      "Train Epoch: 2 [25600/60000]\tLoss: 0.087514\n",
      "Train Epoch: 2 [32000/60000]\tLoss: 0.101167\n",
      "Train Epoch: 2 [38400/60000]\tLoss: 0.195112\n",
      "Train Epoch: 2 [44800/60000]\tLoss: 0.118527\n",
      "Train Epoch: 2 [51200/60000]\tLoss: 0.187379\n",
      "Train Epoch: 2 [57600/60000]\tLoss: 0.045009\n",
      "\n",
      "Test set: Average loss: 0.1042, Accuracy: 9673/10000 (96.73%)\n",
      "\n",
      "Train Epoch: 3 [0/60000]\tLoss: 0.048765\n",
      "Train Epoch: 3 [6400/60000]\tLoss: 0.225744\n",
      "Train Epoch: 3 [12800/60000]\tLoss: 0.050416\n",
      "Train Epoch: 3 [19200/60000]\tLoss: 0.082566\n",
      "Train Epoch: 3 [25600/60000]\tLoss: 0.107061\n",
      "Train Epoch: 3 [32000/60000]\tLoss: 0.011891\n",
      "Train Epoch: 3 [38400/60000]\tLoss: 0.112264\n",
      "Train Epoch: 3 [44800/60000]\tLoss: 0.059840\n",
      "Train Epoch: 3 [51200/60000]\tLoss: 0.034874\n",
      "Train Epoch: 3 [57600/60000]\tLoss: 0.149635\n",
      "\n",
      "Test set: Average loss: 0.0862, Accuracy: 9734/10000 (97.34%)\n",
      "\n",
      "Train Epoch: 4 [0/60000]\tLoss: 0.030343\n",
      "Train Epoch: 4 [6400/60000]\tLoss: 0.063803\n",
      "Train Epoch: 4 [12800/60000]\tLoss: 0.035872\n",
      "Train Epoch: 4 [19200/60000]\tLoss: 0.011557\n",
      "Train Epoch: 4 [25600/60000]\tLoss: 0.275371\n",
      "Train Epoch: 4 [32000/60000]\tLoss: 0.110287\n",
      "Train Epoch: 4 [38400/60000]\tLoss: 0.036932\n",
      "Train Epoch: 4 [44800/60000]\tLoss: 0.011677\n",
      "Train Epoch: 4 [51200/60000]\tLoss: 0.074068\n",
      "Train Epoch: 4 [57600/60000]\tLoss: 0.017879\n",
      "\n",
      "Test set: Average loss: 0.0761, Accuracy: 9764/10000 (97.64%)\n",
      "\n",
      "Train Epoch: 5 [0/60000]\tLoss: 0.056635\n",
      "Train Epoch: 5 [6400/60000]\tLoss: 0.053055\n",
      "Train Epoch: 5 [12800/60000]\tLoss: 0.066328\n",
      "Train Epoch: 5 [19200/60000]\tLoss: 0.053260\n",
      "Train Epoch: 5 [25600/60000]\tLoss: 0.052801\n",
      "Train Epoch: 5 [32000/60000]\tLoss: 0.024395\n",
      "Train Epoch: 5 [38400/60000]\tLoss: 0.035075\n",
      "Train Epoch: 5 [44800/60000]\tLoss: 0.075376\n",
      "Train Epoch: 5 [51200/60000]\tLoss: 0.019631\n",
      "Train Epoch: 5 [57600/60000]\tLoss: 0.015124\n",
      "\n",
      "Test set: Average loss: 0.0687, Accuracy: 9795/10000 (97.95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_no_norm_run = []\n",
    "for runs in range(10):\n",
    "    model = LoRAMLP(r=8).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Train\n",
    "    loss_no_norm = []\n",
    "    for epoch in range(1, 6):\n",
    "        losses = train(model, device, train_loader, optimizer, epoch, layer_norm=False)\n",
    "        test(model, device, test_loader)\n",
    "        loss_no_norm.extend(losses)\n",
    "    loss_no_norm_run.append(loss_no_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f52aa965550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "loss_num_run = np.array(loss_num_run)\n",
    "norm_run_mean = loss_num_run.mean(axis=0)\n",
    "norm_run_sem = stats.sem(loss_num_run, axis=0) * 1.96\n",
    "\n",
    "loss_no_norm_run = np.array(loss_no_norm_run)\n",
    "no_norm_run_mean = loss_no_norm_run.mean(axis=0)\n",
    "no_norm_run_sem = stats.sem(loss_no_norm_run, axis=0) * 1.96\n",
    "\n",
    "length = loss_num_run.shape[1]\n",
    "\n",
    "plt.plot(np.arange(length), norm_run_mean, label=\"Mean across runs\")\n",
    "\n",
    "plt.plot(np.arange(length), no_norm_run_mean, label=\"Mean across runs\")\n",
    "plt.fill_between(np.arange(length), norm_run_mean - norm_run_sem, norm_run_mean + norm_run_sem, alpha=0.3, label=\"95% CI\")\n",
    "\n",
    "plt.fill_between(np.arange(length), no_norm_run_mean - no_norm_run_sem, no_norm_run_mean + no_norm_run_sem, alpha=0.3, label=\"95% CI\")\n",
    "\n",
    "plt.legend([\"w/ norm\", \"w/o norm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
